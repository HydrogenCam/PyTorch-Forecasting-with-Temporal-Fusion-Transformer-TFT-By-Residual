{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyunpack in /Users/guanyuxiaoxiong/opt/anaconda3/envs/tft-env/lib/python3.10/site-packages (0.3)\n",
      "Requirement already satisfied: patool in /Users/guanyuxiaoxiong/opt/anaconda3/envs/tft-env/lib/python3.10/site-packages (4.0.1)\n",
      "Requirement already satisfied: easyprocess in /Users/guanyuxiaoxiong/opt/anaconda3/envs/tft-env/lib/python3.10/site-packages (from pyunpack) (1.1)\n",
      "Requirement already satisfied: entrypoint2 in /Users/guanyuxiaoxiong/opt/anaconda3/envs/tft-env/lib/python3.10/site-packages (from pyunpack) (1.1)\n",
      "Requirement already satisfied: wget in /Users/guanyuxiaoxiong/opt/anaconda3/envs/tft-env/lib/python3.10/site-packages (3.2)\n",
      "Requirement already satisfied: scikit-learn in /Users/guanyuxiaoxiong/opt/anaconda3/envs/tft-env/lib/python3.10/site-packages (1.7.0)\n",
      "Requirement already satisfied: numpy>=1.22.0 in /Users/guanyuxiaoxiong/opt/anaconda3/envs/tft-env/lib/python3.10/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /Users/guanyuxiaoxiong/opt/anaconda3/envs/tft-env/lib/python3.10/site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/guanyuxiaoxiong/opt/anaconda3/envs/tft-env/lib/python3.10/site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/guanyuxiaoxiong/opt/anaconda3/envs/tft-env/lib/python3.10/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: torchvision in /Users/guanyuxiaoxiong/opt/anaconda3/envs/tft-env/lib/python3.10/site-packages (0.17.2)\n",
      "Requirement already satisfied: numpy in /Users/guanyuxiaoxiong/opt/anaconda3/envs/tft-env/lib/python3.10/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: torch==2.2.2 in /Users/guanyuxiaoxiong/opt/anaconda3/envs/tft-env/lib/python3.10/site-packages (from torchvision) (2.2.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/guanyuxiaoxiong/opt/anaconda3/envs/tft-env/lib/python3.10/site-packages (from torchvision) (11.1.0)\n",
      "Requirement already satisfied: filelock in /Users/guanyuxiaoxiong/opt/anaconda3/envs/tft-env/lib/python3.10/site-packages (from torch==2.2.2->torchvision) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/guanyuxiaoxiong/opt/anaconda3/envs/tft-env/lib/python3.10/site-packages (from torch==2.2.2->torchvision) (4.12.2)\n",
      "Requirement already satisfied: sympy in /Users/guanyuxiaoxiong/opt/anaconda3/envs/tft-env/lib/python3.10/site-packages (from torch==2.2.2->torchvision) (1.14.0)\n",
      "Requirement already satisfied: networkx in /Users/guanyuxiaoxiong/opt/anaconda3/envs/tft-env/lib/python3.10/site-packages (from torch==2.2.2->torchvision) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/guanyuxiaoxiong/opt/anaconda3/envs/tft-env/lib/python3.10/site-packages (from torch==2.2.2->torchvision) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /Users/guanyuxiaoxiong/opt/anaconda3/envs/tft-env/lib/python3.10/site-packages (from torch==2.2.2->torchvision) (2025.5.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/guanyuxiaoxiong/opt/anaconda3/envs/tft-env/lib/python3.10/site-packages (from jinja2->torch==2.2.2->torchvision) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/guanyuxiaoxiong/opt/anaconda3/envs/tft-env/lib/python3.10/site-packages (from sympy->torch==2.2.2->torchvision) (1.3.0)\n",
      "Requirement already satisfied: tensorboard in /Users/guanyuxiaoxiong/opt/anaconda3/envs/tft-env/lib/python3.10/site-packages (2.19.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /Users/guanyuxiaoxiong/opt/anaconda3/envs/tft-env/lib/python3.10/site-packages (from tensorboard) (2.3.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /Users/guanyuxiaoxiong/opt/anaconda3/envs/tft-env/lib/python3.10/site-packages (from tensorboard) (1.73.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/guanyuxiaoxiong/opt/anaconda3/envs/tft-env/lib/python3.10/site-packages (from tensorboard) (3.8.2)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /Users/guanyuxiaoxiong/opt/anaconda3/envs/tft-env/lib/python3.10/site-packages (from tensorboard) (1.26.4)\n",
      "Requirement already satisfied: packaging in /Users/guanyuxiaoxiong/opt/anaconda3/envs/tft-env/lib/python3.10/site-packages (from tensorboard) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /Users/guanyuxiaoxiong/opt/anaconda3/envs/tft-env/lib/python3.10/site-packages (from tensorboard) (6.31.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Users/guanyuxiaoxiong/opt/anaconda3/envs/tft-env/lib/python3.10/site-packages (from tensorboard) (78.1.1)\n",
      "Requirement already satisfied: six>1.9 in /Users/guanyuxiaoxiong/opt/anaconda3/envs/tft-env/lib/python3.10/site-packages (from tensorboard) (1.17.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/guanyuxiaoxiong/opt/anaconda3/envs/tft-env/lib/python3.10/site-packages (from tensorboard) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/guanyuxiaoxiong/opt/anaconda3/envs/tft-env/lib/python3.10/site-packages (from tensorboard) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/guanyuxiaoxiong/opt/anaconda3/envs/tft-env/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyunpack patool\n",
    "!pip install wget\n",
    "!pip install scikit-learn\n",
    "!pip install torchvision\n",
    "!pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T03:09:20.062715Z",
     "start_time": "2020-04-22T03:09:18.795699Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyunpack\n",
    "import math\n",
    "import json\n",
    "\n",
    "from data.data_download import Config, download_electricity\n",
    "from data_formatters.base import DataTypes,  InputTypes\n",
    "from data_formatters.electricity import ElectricityFormatter\n",
    "from data.custom_dataset import TFTDataset\n",
    "\n",
    "from models import GatedLinearUnit\n",
    "from models import GateAddNormNetwork\n",
    "from models import GatedResidualNetwork \n",
    "from models import ScaledDotProductAttention\n",
    "from models import InterpretableMultiHeadAttention\n",
    "from models import VariableSelectionNetwork\n",
    "\n",
    "from quantile_loss import QuantileLossCalculator\n",
    "from quantile_loss import NormalizedQuantileLossCalculator\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor\n",
    "from argparse import ArgumentParser\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "import pandas as pd\n",
    "from dateutil import parser\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from pytorch_lightning.callbacks import TQDMProgressBar\n",
    "from pathlib import Path\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose Experiment E0/E1/E2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP = \"E3\"  # \"E0\" | \"E1\" | \"E2\"| \"E3\"\n",
    "\n",
    "if EXP == \"E0\":          \n",
    "    use_tlf = True\n",
    "    tlf_replace_with_seasonal = False\n",
    "    err_target= False\n",
    "elif EXP == \"E1\":       \n",
    "    use_tlf = False\n",
    "    tlf_replace_with_seasonal = False\n",
    "    err_target= False\n",
    "elif EXP == \"E2\":        \n",
    "    use_tlf = True\n",
    "    tlf_replace_with_seasonal = True\n",
    "    err_target= False\n",
    "elif EXP == \"E3\":\n",
    "    use_tlf = True\n",
    "    tlf_replace_with_seasonal = False\n",
    "    err_target= True\n",
    "else:\n",
    "    raise ValueError(\"Unknown EXP\")\n",
    "\n",
    "from data_formatters.electricity import ElectricityFormatter\n",
    "data_formatter = ElectricityFormatter(\n",
    "    use_tlf=use_tlf,\n",
    "    tlf_replace_with_seasonal=tlf_replace_with_seasonal,\n",
    "    err_target=err_target\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data and Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: data/weighted_weather_full.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# === 1. Load and clean weather dataset ===\n",
    "weather_df = pd.read_csv(\"data/archive/weather_features.csv\")\n",
    "weather_df['dt_iso'] = weather_df['dt_iso'].apply(lambda x: parser.parse(x).replace(tzinfo=None))\n",
    "\n",
    "weather_df['city_name'] = weather_df['city_name'].str.strip()\n",
    "weather_df['city_name'] = weather_df['city_name'].replace({\n",
    "    'Sevilla': 'Seville',\n",
    "    'València': 'Valencia'\n",
    "})\n",
    "\n",
    "# === 2. Define population weights (Bilbao replaces Zaragoza)\n",
    "weights = {\n",
    "    \"Madrid\": 0.4804,\n",
    "    \"Barcelona\": 0.2439,\n",
    "    \"Valencia\": 0.1192,\n",
    "    \"Seville\": 0.1044,\n",
    "    \"Bilbao\": 0.0522\n",
    "}\n",
    "weather_df = weather_df[weather_df['city_name'].isin(weights.keys())]\n",
    "\n",
    "# === 3. Weighted numeric aggregation\n",
    "columns_to_weight = [\n",
    "    'temp', 'temp_min', 'temp_max', 'pressure', 'humidity',\n",
    "    'wind_speed', 'wind_deg', 'rain_1h', 'rain_3h', 'snow_3h', 'clouds_all'\n",
    "]\n",
    "\n",
    "for col in columns_to_weight:\n",
    "    weather_df[col + '_weighted'] = weather_df.apply(\n",
    "        lambda row: row[col] * weights[row['city_name']], axis=1\n",
    "    )\n",
    "\n",
    "weighted_numeric = weather_df.groupby('dt_iso').agg({\n",
    "    col + '_weighted': 'sum' for col in columns_to_weight\n",
    "}).reset_index()\n",
    "\n",
    "# === 4. Simplify weather_description\n",
    "top_desc = weather_df['weather_description'].value_counts()\n",
    "top_desc = top_desc[top_desc > 100].index\n",
    "weather_df['weather_description_simplified'] = weather_df['weather_description'].where(\n",
    "    weather_df['weather_description'].isin(top_desc), other='other'\n",
    ")\n",
    "\n",
    "# === 5. Aggregate categorical and ID fields\n",
    "def mode(series):\n",
    "    return series.mode().iloc[0] if not series.mode().empty else 'unknown'\n",
    "\n",
    "categorical_agg = weather_df.groupby('dt_iso').agg({\n",
    "    'weather_main': mode,\n",
    "    'weather_description_simplified': mode,\n",
    "}).reset_index()\n",
    "\n",
    "# === 6. Merge all weather features\n",
    "weather_final = pd.merge(weighted_numeric, categorical_agg, on='dt_iso')\n",
    "weather_final.rename(columns={'dt_iso': 'time'}, inplace=True)\n",
    "\n",
    "# === 7. Load and clean energy dataset\n",
    "energy_df = pd.read_csv(\"data/archive/energy_dataset.csv\")\n",
    "energy_df['time'] = energy_df['time'].apply(lambda x: parser.parse(x).replace(tzinfo=None))\n",
    "\n",
    "# === 8. Merge energy + weather\n",
    "merged_df = pd.merge(energy_df, weather_final, on='time', how='inner')\n",
    "\n",
    "# === 9. Save result to final path\n",
    "output_path = \"data/weighted_weather_full.csv\"\n",
    "merged_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(\"✅ Saved:\", output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === 1. Load original data ===\n",
    "df = pd.read_csv(\"data/weighted_weather_full.csv\")\n",
    "\n",
    "# === 2. Drop columns that are completely empty ===\n",
    "df = df.dropna(axis=1, how='all')\n",
    "\n",
    "# === 3. Drop rows where 'total load actual' (your target) is missing ===\n",
    "df = df[df['total load actual'].notna()]\n",
    "\n",
    "# === 4. Identify numeric columns and fill missing values ===\n",
    "numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "if 'days_from_start' in numeric_cols:\n",
    "    numeric_cols.remove('days_from_start')  # leave it alone\n",
    "\n",
    "# Forward fill first, then fill remaining NaNs with column medians\n",
    "df[numeric_cols] = df[numeric_cols].fillna(method='ffill')\n",
    "df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].median())\n",
    "\n",
    "# === 5. Handle categorical variables: fill with 'unknown' ===\n",
    "categorical_cols = ['weather_main', 'weather_description_simplified']\n",
    "for col in categorical_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].fillna('unknown')\n",
    "\n",
    "# === 6. Save cleaned dataset ===\n",
    "df.to_csv(\"data/weighted_weather_full_clean.csv\", index=False)\n",
    "\n",
    "print(\"✅ Data cleaned and saved as: weighted_weather_full_clean.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === 1. Load the merged energy + weather dataset ===\n",
    "df = pd.read_csv(\"data/weighted_weather_full_clean.csv\")\n",
    "\n",
    "# === 2. Convert time column to datetime ===\n",
    "df['time'] = pd.to_datetime(df['time'])\n",
    "\n",
    "# === 3. Create 'days_from_start' (integer offset from first date) ===\n",
    "df['days_from_start'] = (df['time'] - df['time'].min()).dt.days\n",
    "\n",
    "# === 4. Extract time features ===\n",
    "df['hour'] = df['time'].dt.hour\n",
    "df['day_of_week'] = df['time'].dt.dayofweek  # Monday=0, Sunday=6\n",
    "\n",
    "# === 5. Add 'id' column (static identifier) ===\n",
    "df['identifier'] = 'Spain'\n",
    "# === 6. Seasonal baseline (for tlf_replace_with_seasonal) ===\n",
    "df['_time_order'] = df['days_from_start'] * 24 + df['hour'].astype(int)\n",
    "df = df.sort_values(['identifier', '_time_order'])\n",
    "if 'split' not in df.columns:\n",
    "    def _make_splits(g, train_frac=0.8, val_frac=0.1):\n",
    "        n = len(g)\n",
    "        i1 = int(n * train_frac)\n",
    "        i2 = int(n * (train_frac + val_frac))\n",
    "        lab = np.array(['train'] * n)\n",
    "        lab[i1:i2] = 'val'\n",
    "        lab[i2:]   = 'test'\n",
    "        g['split'] = lab\n",
    "        return g\n",
    "    df = df.groupby('identifier', group_keys=False).apply(_make_splits)\n",
    "\n",
    "#  Hour-of-week key: same hour & weekday share seasonal pattern\n",
    "df['hour_of_week'] = df['day_of_week'].astype(int) * 24 + df['hour'].astype(int)\n",
    "doy = (df['days_from_start'] % 365).astype(int)          # approx day-of-year\n",
    "df['month_bin'] = (doy // 30).clip(0, 11) + 1            # 1..12 approx\n",
    "\n",
    "# Seasonal baseline: use only past values (shift(1) then rolling)\n",
    "K = 8  # past 8 weeks; try 4/12 for sensitivity analysis\n",
    "df['seasonal_baseline'] = (\n",
    "    df.groupby(['identifier', 'hour_of_week'])['total load actual']\n",
    "      .transform(lambda s: s.shift(1).rolling(K, min_periods=1).median()))\n",
    "# Fallback #1: expanding median on same hour_of_week (past-only)\n",
    "mask = df['seasonal_baseline'].isna()\n",
    "if mask.any():\n",
    "    exp_hw = (\n",
    "        df.groupby(['identifier', 'hour_of_week'])['total load actual']\n",
    "          .transform(lambda s: s.shift(1).expanding().median())\n",
    "    )\n",
    "    df.loc[mask, 'seasonal_baseline'] = exp_hw[mask]\n",
    "\n",
    "# Fallback #2: expanding median on coarser month_bin × hour (past-only)\n",
    "mask = df['seasonal_baseline'].isna()\n",
    "if mask.any():\n",
    "    exp_mh = (\n",
    "        df.groupby(['identifier', 'month_bin', 'hour'])['total load actual']\n",
    "          .transform(lambda s: s.shift(1).expanding().median())\n",
    "    )\n",
    "    df.loc[mask, 'seasonal_baseline'] = exp_mh[mask]\n",
    "\n",
    "# Fallback #3: expanding median per identifier (past-only)\n",
    "mask = df['seasonal_baseline'].isna()\n",
    "if mask.any():\n",
    "    exp_id = (\n",
    "        df.groupby('identifier')['total load actual']\n",
    "          .transform(lambda s: s.shift(1).expanding().median())\n",
    "    )\n",
    "    df.loc[mask, 'seasonal_baseline'] = exp_id[mask]\n",
    "df.drop(columns=['_time_order'], inplace=True)\n",
    "still = df['seasonal_baseline'].isna()\n",
    "if still.any():\n",
    "    id_med = (df.loc[df['split']=='train']\n",
    "                .groupby('identifier')['total load actual']\n",
    "                .median())\n",
    "    df.loc[still,'seasonal_baseline'] = df.loc[still,'identifier'].map(id_med)\n",
    "# === 7. Rename target column ===\n",
    "df.rename(columns={'total load actual': 'target'}, inplace=True)\n",
    "\n",
    "# Residual/error target: actual - provided prediction\n",
    "df['err_target'] = df['target'] - df['total load forecast']\n",
    "\n",
    "\n",
    "# === 8. Save the cleaned dataset ===\n",
    "df.to_csv(\"data/electricty.csv\", index=False)\n",
    "\n",
    "print(\"✅ Done: 'hour', 'day_of_week', 'days_from_start', 'id' added, target renamed, file saved.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📋 All column names:\n",
      "['time', 'generation biomass', 'generation fossil brown coal/lignite', 'generation fossil coal-derived gas', 'generation fossil gas', 'generation fossil hard coal', 'generation fossil oil', 'generation fossil oil shale', 'generation fossil peat', 'generation geothermal', 'generation hydro pumped storage consumption', 'generation hydro run-of-river and poundage', 'generation hydro water reservoir', 'generation marine', 'generation nuclear', 'generation other', 'generation other renewable', 'generation solar', 'generation waste', 'generation wind offshore', 'generation wind onshore', 'forecast solar day ahead', 'forecast wind onshore day ahead', 'total load forecast', 'target', 'price day ahead', 'price actual', 'temp_weighted', 'temp_min_weighted', 'temp_max_weighted', 'pressure_weighted', 'humidity_weighted', 'wind_speed_weighted', 'wind_deg_weighted', 'rain_1h_weighted', 'rain_3h_weighted', 'snow_3h_weighted', 'clouds_all_weighted', 'weather_main', 'weather_description_simplified', 'days_from_start', 'hour', 'day_of_week', 'identifier', 'split', 'hour_of_week', 'month_bin', 'seasonal_baseline', 'err_target']\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/electricty.csv\")\n",
    "print(\"📋 All column names:\")\n",
    "print(df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T03:09:29.304537Z",
     "start_time": "2020-04-22T03:09:20.960449Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatting train-valid-test splits.\n",
      "Setting scalers with training data...\n"
     ]
    }
   ],
   "source": [
    "electricity = pd.read_csv('data/electricty.csv', index_col = 0)\n",
    "train, valid, test = data_formatter.split_data(electricity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNOWN(real) from formatter: ['hour', 'day_of_week', 'forecast solar day ahead', 'forecast wind onshore day ahead', 'price day ahead', 'temp_weighted', 'temp_min_weighted', 'temp_max_weighted', 'pressure_weighted', 'humidity_weighted', 'wind_speed_weighted', 'wind_deg_weighted', 'rain_1h_weighted', 'rain_3h_weighted', 'snow_3h_weighted', 'clouds_all_weighted', 'total load forecast']\n",
      "train columns: ['identifier', 'days_from_start', 'err_target', 'hour', 'day_of_week', 'forecast solar day ahead', 'forecast wind onshore day ahead', 'price day ahead', 'temp_weighted', 'temp_min_weighted', 'temp_max_weighted', 'pressure_weighted'] ... (# 43 )\n"
     ]
    }
   ],
   "source": [
    "# ==== helper: keep only model columns based on column_definition ====\n",
    "def filter_to_model_columns(df, coldef):\n",
    "    \"\"\"Whitelist columns that appear in the model's column definition.\"\"\"\n",
    "    keep = [name for (name, _, _) in coldef if name in df.columns]\n",
    "    return df.loc[:, keep].copy()\n",
    "\n",
    "# get current column definition from formatter\n",
    "coldef = (data_formatter.get_column_definition()\n",
    "          if hasattr(data_formatter, \"get_column_definition\")\n",
    "          else data_formatter._column_definition)\n",
    "# ==== E2 only: ensure 'seasonal_baseline' exists in all splits ====\n",
    "if tlf_replace_with_seasonal:\n",
    "    # If the column is already in the CSV/splits, just sanity-fix dtype & NaNs.\n",
    "    has_all = all(\"seasonal_baseline\" in df_.columns for df_ in (train, valid, test))\n",
    "\n",
    "    if has_all:\n",
    "        for name, d in ((\"train\", train), (\"valid\", valid), (\"test\", test)):\n",
    "            d[\"seasonal_baseline\"] = pd.to_numeric(d[\"seasonal_baseline\"], errors=\"coerce\")\n",
    "            if d[\"seasonal_baseline\"].isna().any():\n",
    "                d[\"seasonal_baseline\"] = d[\"seasonal_baseline\"].fillna(train[\"target\"].median())\n",
    "        # nothing else to do\n",
    "    else:\n",
    "        # build from TRAIN ONLY to avoid leakage, using available keys\n",
    "        keys = [k for k in (\"day_of_week\", \"hour\") if k in train.columns]\n",
    "        if len(keys) >= 1:\n",
    "            base = (\n",
    "                train.groupby(keys)[\"target\"]\n",
    "                     .median()\n",
    "                     .reset_index()\n",
    "                     .rename(columns={\"target\": \"seasonal_baseline\"})\n",
    "            )\n",
    "\n",
    "            def _merge_and_fix(df):\n",
    "                # drop any existing same-named col to prevent _x/_y suffixes\n",
    "                if \"seasonal_baseline\" in df.columns:\n",
    "                    df = df.drop(columns=[\"seasonal_baseline\"])\n",
    "                merged = df.merge(base, on=keys, how=\"left\", copy=False)\n",
    "                if merged[\"seasonal_baseline\"].isna().any():\n",
    "                    merged[\"seasonal_baseline\"] = merged[\"seasonal_baseline\"].fillna(train[\"target\"].median())\n",
    "                return merged\n",
    "\n",
    "            train = _merge_and_fix(train)\n",
    "            valid = _merge_and_fix(valid)\n",
    "            test  = _merge_and_fix(test)\n",
    "        else:\n",
    "            # last resort: global median from TRAIN\n",
    "            sb = float(train[\"target\"].median())\n",
    "            for d in (train, valid, test):\n",
    "                d[\"seasonal_baseline\"] = sb\n",
    "# else: nothing to do for E1\n",
    "\n",
    "# ==== whitelist columns (works for both E1 and E2) ====\n",
    "train = filter_to_model_columns(train, coldef)\n",
    "valid = filter_to_model_columns(valid, coldef)\n",
    "test  = filter_to_model_columns(test,  coldef)\n",
    "\n",
    "# ==== quick sanity checks ====\n",
    "known_cols = [n for (n, dt, role) in coldef\n",
    "              if role == InputTypes.KNOWN_INPUT and dt == DataTypes.REAL_VALUED]\n",
    "print(\"KNOWN(real) from formatter:\", known_cols)\n",
    "print(\"train columns:\", list(train.columns)[:12], \"... (#\", len(train.columns), \")\")\n",
    "\n",
    "if EXP == \"E1\":\n",
    "    assert \"total load forecast\" not in known_cols\n",
    "    assert \"total load forecast\" not in train.columns\n",
    "if EXP == \"E2\":\n",
    "    assert \"seasonal_baseline\" in known_cols, \"E2: seasonal_baseline must be KNOWN input.\"\n",
    "    assert \"seasonal_baseline\" in train.columns, \"E2: seasonal_baseline missing in dataframes.\"\n",
    "\n",
    "            \n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T02:56:55.662935Z",
     "start_time": "2020-04-22T02:56:55.659314Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((31523, 43), (744, 43), (3097, 43))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, valid.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T02:56:55.700490Z",
     "start_time": "2020-04-22T02:56:55.664219Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>days_from_start</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1313</th>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>1310</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>1311</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>1312</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>1313</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1138</th>\n",
       "      <td>1314</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1315 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      days_from_start  count\n",
       "11                  0     24\n",
       "654                 1     24\n",
       "876                 2     24\n",
       "875                 3     24\n",
       "1313                4     18\n",
       "...               ...    ...\n",
       "437              1310     24\n",
       "436              1311     24\n",
       "435              1312     24\n",
       "434              1313     24\n",
       "1138             1314     24\n",
       "\n",
       "[1315 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.days_from_start.value_counts().to_frame().reset_index().sort_values(by='days_from_start')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T02:56:55.714718Z",
     "start_time": "2020-04-22T02:56:55.702319Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>days_from_start</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1308</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1309</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1310</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1311</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1312</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1313</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1314</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1315</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1316</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1317</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1318</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1319</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1320</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1321</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1322</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1323</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1324</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1325</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1326</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1327</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1328</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1329</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1330</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1331</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1332</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1333</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1334</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1335</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1336</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1337</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1338</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    days_from_start  count\n",
       "0              1308     24\n",
       "16             1309     24\n",
       "29             1310     24\n",
       "28             1311     24\n",
       "27             1312     24\n",
       "26             1313     24\n",
       "25             1314     24\n",
       "24             1315     24\n",
       "23             1316     24\n",
       "22             1317     24\n",
       "21             1318     24\n",
       "20             1319     24\n",
       "19             1320     24\n",
       "18             1321     24\n",
       "17             1322     24\n",
       "15             1323     24\n",
       "1              1324     24\n",
       "14             1325     24\n",
       "13             1326     24\n",
       "12             1327     24\n",
       "11             1328     24\n",
       "10             1329     24\n",
       "9              1330     24\n",
       "8              1331     24\n",
       "7              1332     24\n",
       "6              1333     24\n",
       "5              1334     24\n",
       "4              1335     24\n",
       "3              1336     24\n",
       "2              1337     24\n",
       "30             1338     24"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid.days_from_start.value_counts().to_frame().reset_index().sort_values(by='days_from_start')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T02:56:55.725026Z",
     "start_time": "2020-04-22T02:56:55.715893Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>days_from_start</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>1332</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>1333</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1334</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>1335</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>1336</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1456</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1457</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1458</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1459</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>1460</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>129 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     days_from_start  count\n",
       "64              1332     24\n",
       "65              1333     24\n",
       "95              1334     24\n",
       "94              1335     24\n",
       "93              1336     24\n",
       "..               ...    ...\n",
       "38              1456     24\n",
       "37              1457     24\n",
       "36              1458     24\n",
       "35              1459     24\n",
       "128             1460     24\n",
       "\n",
       "[129 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.days_from_start.value_counts().to_frame().reset_index().sort_values(by=['days_from_start'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reviewing Test dataset error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-29T01:17:20.633823Z",
     "start_time": "2020-03-29T01:17:20.591206Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identifier</th>\n",
       "      <th>days_from_start</th>\n",
       "      <th>err_target</th>\n",
       "      <th>hour</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>forecast solar day ahead</th>\n",
       "      <th>forecast wind onshore day ahead</th>\n",
       "      <th>price day ahead</th>\n",
       "      <th>temp_weighted</th>\n",
       "      <th>temp_min_weighted</th>\n",
       "      <th>...</th>\n",
       "      <th>generation marine</th>\n",
       "      <th>generation nuclear</th>\n",
       "      <th>generation other</th>\n",
       "      <th>generation other renewable</th>\n",
       "      <th>generation solar</th>\n",
       "      <th>generation waste</th>\n",
       "      <th>generation wind offshore</th>\n",
       "      <th>generation wind onshore</th>\n",
       "      <th>weather_main</th>\n",
       "      <th>weather_description_simplified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Spain</td>\n",
       "      <td>1332</td>\n",
       "      <td>1.012600</td>\n",
       "      <td>-1.660795</td>\n",
       "      <td>0.999770</td>\n",
       "      <td>-0.657755</td>\n",
       "      <td>0.093105</td>\n",
       "      <td>1.082419</td>\n",
       "      <td>0.116072</td>\n",
       "      <td>0.140691</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.834974</td>\n",
       "      <td>-0.173525</td>\n",
       "      <td>1.547250</td>\n",
       "      <td>-0.606260</td>\n",
       "      <td>1.078413</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.057872</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spain</td>\n",
       "      <td>1332</td>\n",
       "      <td>0.980120</td>\n",
       "      <td>-1.516366</td>\n",
       "      <td>0.999770</td>\n",
       "      <td>-0.675507</td>\n",
       "      <td>0.042002</td>\n",
       "      <td>0.889354</td>\n",
       "      <td>0.085624</td>\n",
       "      <td>0.123137</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.838553</td>\n",
       "      <td>-0.173525</td>\n",
       "      <td>1.547250</td>\n",
       "      <td>-0.671879</td>\n",
       "      <td>1.058808</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.032227</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spain</td>\n",
       "      <td>1332</td>\n",
       "      <td>0.804725</td>\n",
       "      <td>-1.371937</td>\n",
       "      <td>0.999770</td>\n",
       "      <td>-0.706277</td>\n",
       "      <td>-0.049544</td>\n",
       "      <td>0.801534</td>\n",
       "      <td>0.056716</td>\n",
       "      <td>0.098096</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.843325</td>\n",
       "      <td>-0.173525</td>\n",
       "      <td>1.404449</td>\n",
       "      <td>-0.744001</td>\n",
       "      <td>1.039204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.137861</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Spain</td>\n",
       "      <td>1332</td>\n",
       "      <td>0.527558</td>\n",
       "      <td>-1.227508</td>\n",
       "      <td>0.999770</td>\n",
       "      <td>-0.725805</td>\n",
       "      <td>-0.143599</td>\n",
       "      <td>0.662137</td>\n",
       "      <td>0.025070</td>\n",
       "      <td>0.062054</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.848096</td>\n",
       "      <td>-0.221066</td>\n",
       "      <td>1.333048</td>\n",
       "      <td>-0.802526</td>\n",
       "      <td>1.019599</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.214601</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Spain</td>\n",
       "      <td>1332</td>\n",
       "      <td>0.438778</td>\n",
       "      <td>-1.083079</td>\n",
       "      <td>0.999770</td>\n",
       "      <td>-0.740598</td>\n",
       "      <td>-0.221037</td>\n",
       "      <td>0.627288</td>\n",
       "      <td>-0.010182</td>\n",
       "      <td>0.013126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.852868</td>\n",
       "      <td>-0.221066</td>\n",
       "      <td>1.475849</td>\n",
       "      <td>-0.817305</td>\n",
       "      <td>0.980390</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.231378</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3092</th>\n",
       "      <td>Spain</td>\n",
       "      <td>1460</td>\n",
       "      <td>0.113972</td>\n",
       "      <td>1.083358</td>\n",
       "      <td>-1.500369</td>\n",
       "      <td>-0.809831</td>\n",
       "      <td>-0.696954</td>\n",
       "      <td>1.418365</td>\n",
       "      <td>-0.359285</td>\n",
       "      <td>-0.363656</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.232667</td>\n",
       "      <td>0.111724</td>\n",
       "      <td>0.761843</td>\n",
       "      <td>-0.813166</td>\n",
       "      <td>0.215814</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.733450</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3093</th>\n",
       "      <td>Spain</td>\n",
       "      <td>1460</td>\n",
       "      <td>-0.386228</td>\n",
       "      <td>1.227787</td>\n",
       "      <td>-1.500369</td>\n",
       "      <td>-0.836459</td>\n",
       "      <td>-0.665602</td>\n",
       "      <td>1.387001</td>\n",
       "      <td>-0.446290</td>\n",
       "      <td>-0.459454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.231474</td>\n",
       "      <td>0.064182</td>\n",
       "      <td>0.761843</td>\n",
       "      <td>-0.843907</td>\n",
       "      <td>0.274627</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.679079</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3094</th>\n",
       "      <td>Spain</td>\n",
       "      <td>1460</td>\n",
       "      <td>0.404132</td>\n",
       "      <td>1.372216</td>\n",
       "      <td>-1.500369</td>\n",
       "      <td>-0.845335</td>\n",
       "      <td>-0.649613</td>\n",
       "      <td>1.281059</td>\n",
       "      <td>-0.494750</td>\n",
       "      <td>-0.473481</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.229088</td>\n",
       "      <td>0.016641</td>\n",
       "      <td>0.690443</td>\n",
       "      <td>-0.845089</td>\n",
       "      <td>0.392255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.612281</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3095</th>\n",
       "      <td>Spain</td>\n",
       "      <td>1460</td>\n",
       "      <td>0.800394</td>\n",
       "      <td>1.516645</td>\n",
       "      <td>-1.500369</td>\n",
       "      <td>-0.849477</td>\n",
       "      <td>-0.690683</td>\n",
       "      <td>1.075449</td>\n",
       "      <td>-0.538937</td>\n",
       "      <td>-0.535750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.230281</td>\n",
       "      <td>0.016641</td>\n",
       "      <td>0.619042</td>\n",
       "      <td>-0.845089</td>\n",
       "      <td>0.411859</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.586494</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3096</th>\n",
       "      <td>Spain</td>\n",
       "      <td>1460</td>\n",
       "      <td>0.107476</td>\n",
       "      <td>1.661074</td>\n",
       "      <td>-1.500369</td>\n",
       "      <td>-0.851253</td>\n",
       "      <td>-0.739592</td>\n",
       "      <td>1.099146</td>\n",
       "      <td>-0.576312</td>\n",
       "      <td>-0.573056</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.230281</td>\n",
       "      <td>0.016641</td>\n",
       "      <td>0.547642</td>\n",
       "      <td>-0.845089</td>\n",
       "      <td>0.411859</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.566300</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3097 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     identifier  days_from_start  err_target      hour  day_of_week  \\\n",
       "0         Spain             1332    1.012600 -1.660795     0.999770   \n",
       "1         Spain             1332    0.980120 -1.516366     0.999770   \n",
       "2         Spain             1332    0.804725 -1.371937     0.999770   \n",
       "3         Spain             1332    0.527558 -1.227508     0.999770   \n",
       "4         Spain             1332    0.438778 -1.083079     0.999770   \n",
       "...         ...              ...         ...       ...          ...   \n",
       "3092      Spain             1460    0.113972  1.083358    -1.500369   \n",
       "3093      Spain             1460   -0.386228  1.227787    -1.500369   \n",
       "3094      Spain             1460    0.404132  1.372216    -1.500369   \n",
       "3095      Spain             1460    0.800394  1.516645    -1.500369   \n",
       "3096      Spain             1460    0.107476  1.661074    -1.500369   \n",
       "\n",
       "      forecast solar day ahead  forecast wind onshore day ahead  \\\n",
       "0                    -0.657755                         0.093105   \n",
       "1                    -0.675507                         0.042002   \n",
       "2                    -0.706277                        -0.049544   \n",
       "3                    -0.725805                        -0.143599   \n",
       "4                    -0.740598                        -0.221037   \n",
       "...                        ...                              ...   \n",
       "3092                 -0.809831                        -0.696954   \n",
       "3093                 -0.836459                        -0.665602   \n",
       "3094                 -0.845335                        -0.649613   \n",
       "3095                 -0.849477                        -0.690683   \n",
       "3096                 -0.851253                        -0.739592   \n",
       "\n",
       "      price day ahead  temp_weighted  temp_min_weighted  ...  \\\n",
       "0            1.082419       0.116072           0.140691  ...   \n",
       "1            0.889354       0.085624           0.123137  ...   \n",
       "2            0.801534       0.056716           0.098096  ...   \n",
       "3            0.662137       0.025070           0.062054  ...   \n",
       "4            0.627288      -0.010182           0.013126  ...   \n",
       "...               ...            ...                ...  ...   \n",
       "3092         1.418365      -0.359285          -0.363656  ...   \n",
       "3093         1.387001      -0.446290          -0.459454  ...   \n",
       "3094         1.281059      -0.494750          -0.473481  ...   \n",
       "3095         1.075449      -0.538937          -0.535750  ...   \n",
       "3096         1.099146      -0.576312          -0.573056  ...   \n",
       "\n",
       "      generation marine  generation nuclear  generation other  \\\n",
       "0                   0.0            0.834974         -0.173525   \n",
       "1                   0.0            0.838553         -0.173525   \n",
       "2                   0.0            0.843325         -0.173525   \n",
       "3                   0.0            0.848096         -0.221066   \n",
       "4                   0.0            0.852868         -0.221066   \n",
       "...                 ...                 ...               ...   \n",
       "3092                0.0           -0.232667          0.111724   \n",
       "3093                0.0           -0.231474          0.064182   \n",
       "3094                0.0           -0.229088          0.016641   \n",
       "3095                0.0           -0.230281          0.016641   \n",
       "3096                0.0           -0.230281          0.016641   \n",
       "\n",
       "      generation other renewable  generation solar  generation waste  \\\n",
       "0                       1.547250         -0.606260          1.078413   \n",
       "1                       1.547250         -0.671879          1.058808   \n",
       "2                       1.404449         -0.744001          1.039204   \n",
       "3                       1.333048         -0.802526          1.019599   \n",
       "4                       1.475849         -0.817305          0.980390   \n",
       "...                          ...               ...               ...   \n",
       "3092                    0.761843         -0.813166          0.215814   \n",
       "3093                    0.761843         -0.843907          0.274627   \n",
       "3094                    0.690443         -0.845089          0.392255   \n",
       "3095                    0.619042         -0.845089          0.411859   \n",
       "3096                    0.547642         -0.845089          0.411859   \n",
       "\n",
       "      generation wind offshore  generation wind onshore  weather_main  \\\n",
       "0                          0.0                 0.057872             0   \n",
       "1                          0.0                -0.032227             0   \n",
       "2                          0.0                -0.137861             0   \n",
       "3                          0.0                -0.214601             0   \n",
       "4                          0.0                -0.231378             0   \n",
       "...                        ...                      ...           ...   \n",
       "3092                       0.0                -0.733450             0   \n",
       "3093                       0.0                -0.679079             0   \n",
       "3094                       0.0                -0.612281             0   \n",
       "3095                       0.0                -0.586494             0   \n",
       "3096                       0.0                -0.566300             0   \n",
       "\n",
       "      weather_description_simplified  \n",
       "0                                 19  \n",
       "1                                 19  \n",
       "2                                 19  \n",
       "3                                 19  \n",
       "4                                 19  \n",
       "...                              ...  \n",
       "3092                              19  \n",
       "3093                              19  \n",
       "3094                              19  \n",
       "3095                              19  \n",
       "3096                              19  \n",
       "\n",
       "[3097 rows x 43 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = test.reset_index(drop=True)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['identifier', 'days_from_start', 'err_target', 'hour', 'day_of_week', 'forecast solar day ahead', 'forecast wind onshore day ahead', 'price day ahead', 'temp_weighted', 'temp_min_weighted', 'temp_max_weighted', 'pressure_weighted', 'humidity_weighted', 'wind_speed_weighted', 'wind_deg_weighted', 'rain_1h_weighted', 'rain_3h_weighted', 'snow_3h_weighted', 'clouds_all_weighted', 'total load forecast', 'price actual', 'generation biomass', 'generation fossil brown coal/lignite', 'generation fossil coal-derived gas', 'generation fossil gas', 'generation fossil hard coal', 'generation fossil oil', 'generation fossil oil shale', 'generation fossil peat', 'generation geothermal', 'generation hydro pumped storage consumption', 'generation hydro run-of-river and poundage', 'generation hydro water reservoir', 'generation marine', 'generation nuclear', 'generation other', 'generation other renewable', 'generation solar', 'generation waste', 'generation wind offshore', 'generation wind onshore', 'weather_main', 'weather_description_simplified']\n"
     ]
    }
   ],
   "source": [
    "print(test.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T03:09:35.347675Z",
     "start_time": "2020-04-22T03:09:29.305754Z"
    }
   },
   "outputs": [],
   "source": [
    "params = {}\n",
    "params.update(data_formatter.get_experiment_params())\n",
    "params.update(data_formatter.get_default_model_params())\n",
    "parser = ArgumentParser(add_help=False)\n",
    "\n",
    "\n",
    "\n",
    "train_dataset = TFTDataset(train,  formatter=data_formatter)\n",
    "valid_dataset = TFTDataset(valid, formatter=data_formatter)\n",
    "test_dataset  = TFTDataset(test,  formatter=data_formatter)\n",
    "\n",
    "for k in params:\n",
    "    if type(params[k]) in [int, float]:\n",
    "        #if k == 'minibatch_size':\n",
    "        #    parser.add_argument('--{}'.format(k), type=type(params[k]), default = 256)\n",
    "        #else:\n",
    "        parser.add_argument('--{}'.format(k), type=type(params[k]), default = params[k])\n",
    "    else:\n",
    "        parser.add_argument('--{}'.format(k), type=str, default = str(params[k]))\n",
    "hparams = parser.parse_known_args()[0]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T02:57:13.230902Z",
     "start_time": "2020-04-22T02:57:13.227547Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31331, 552, 2905)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(valid_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T02:57:13.238349Z",
     "start_time": "2020-04-22T02:57:13.232842Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31331, 552, 2905)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(valid_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temporal Fusion Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T03:09:35.415971Z",
     "start_time": "2020-04-22T03:09:35.349298Z"
    },
    "code_folding": [
     1,
     98,
     114,
     134,
     144,
     153,
     174,
     188,
     196,
     202,
     207,
     217,
     226,
     242,
     301,
     446,
     449,
     452,
     467,
     478,
     483,
     491,
     497,
     526
    ]
   },
   "outputs": [],
   "source": [
    "class TemporalFusionTransformer(pl.LightningModule):\n",
    "    def __init__(self, hparams):\n",
    "        super(TemporalFusionTransformer, self).__init__()\n",
    "        \n",
    "        \n",
    "        self.save_hyperparameters(vars(hparams))\n",
    "        self.hparams_ns = hparams\n",
    "    \n",
    "        self.name = self.__class__.__name__\n",
    "\n",
    "        # Data parameters\n",
    "        self.time_steps = int(hparams.total_time_steps)#int(params['total_time_steps'])\n",
    "        self.input_size = int(hparams.input_size)#int(params['input_size'])\n",
    "        self.output_size = int(hparams.output_size)#int(params['output_size'])\n",
    "        self.category_counts = json.loads(str(hparams.category_counts))#json.loads(str(params['category_counts']))\n",
    "        self.num_categorical_variables = len(self.category_counts)\n",
    "        self.num_regular_variables = self.input_size - self.num_categorical_variables\n",
    "        self.n_multiprocessing_workers = int(hparams.multiprocessing_workers) #int(params['multiprocessing_workers'])\n",
    "\n",
    "       \n",
    "        # --- Known future inputs (build progressively to honor switches) ---\n",
    "        _known_block = [\n",
    "    ('hour', DataTypes.REAL_VALUED, InputTypes.KNOWN_INPUT),\n",
    "    ('day_of_week', DataTypes.REAL_VALUED, InputTypes.KNOWN_INPUT),\n",
    "    ('forecast solar day ahead', DataTypes.REAL_VALUED, InputTypes.KNOWN_INPUT),\n",
    "    ('forecast wind onshore day ahead', DataTypes.REAL_VALUED, InputTypes.KNOWN_INPUT),\n",
    "    ('price day ahead', DataTypes.REAL_VALUED, InputTypes.KNOWN_INPUT),\n",
    "    ('temp_weighted', DataTypes.REAL_VALUED, InputTypes.KNOWN_INPUT),\n",
    "    ('temp_min_weighted', DataTypes.REAL_VALUED, InputTypes.KNOWN_INPUT),\n",
    "    ('temp_max_weighted', DataTypes.REAL_VALUED, InputTypes.KNOWN_INPUT),\n",
    "    ('pressure_weighted', DataTypes.REAL_VALUED, InputTypes.KNOWN_INPUT),\n",
    "    ('humidity_weighted', DataTypes.REAL_VALUED, InputTypes.KNOWN_INPUT),\n",
    "    ('wind_speed_weighted', DataTypes.REAL_VALUED, InputTypes.KNOWN_INPUT),\n",
    "    ('wind_deg_weighted', DataTypes.REAL_VALUED, InputTypes.KNOWN_INPUT),\n",
    "    ('rain_1h_weighted', DataTypes.REAL_VALUED, InputTypes.KNOWN_INPUT),\n",
    "    ('rain_3h_weighted', DataTypes.REAL_VALUED, InputTypes.KNOWN_INPUT),\n",
    "    ('snow_3h_weighted', DataTypes.REAL_VALUED, InputTypes.KNOWN_INPUT),\n",
    "    ('clouds_all_weighted', DataTypes.REAL_VALUED, InputTypes.KNOWN_INPUT),\n",
    "      ]\n",
    "        if getattr(self.hparams, \"tlf_replace_with_seasonal\", False):\n",
    "            _known_block.append(('seasonal_baseline', DataTypes.REAL_VALUED, InputTypes.KNOWN_INPUT))\n",
    "        elif getattr(self.hparams, \"use_tlf\", True):\n",
    "            _known_block.append(('total load forecast', DataTypes.REAL_VALUED, InputTypes.KNOWN_INPUT))\n",
    "\n",
    "        core = [\n",
    "            ('identifier', DataTypes.CATEGORICAL, InputTypes.ID),\n",
    "            ('days_from_start', DataTypes.REAL_VALUED, InputTypes.TIME),\n",
    "        ]\n",
    "        if getattr(self.hparams, \"err_target\", False):\n",
    "            core.append(('err_target', DataTypes.REAL_VALUED, InputTypes.TARGET))\n",
    "        else:\n",
    "            core.append(('target', DataTypes.REAL_VALUED, InputTypes.TARGET))\n",
    "                        \n",
    "        \n",
    "        self.column_definition =core+_known_block+[\n",
    "\n",
    "    # --- Observed real inputs ---\n",
    "    ('price actual', DataTypes.REAL_VALUED, InputTypes.OBSERVED_INPUT),\n",
    "    ('generation biomass', DataTypes.REAL_VALUED, InputTypes.OBSERVED_INPUT),\n",
    "    ('generation fossil brown coal/lignite', DataTypes.REAL_VALUED, InputTypes.OBSERVED_INPUT),\n",
    "    ('generation fossil coal-derived gas', DataTypes.REAL_VALUED, InputTypes.OBSERVED_INPUT),\n",
    "    ('generation fossil gas', DataTypes.REAL_VALUED, InputTypes.OBSERVED_INPUT),\n",
    "    ('generation fossil hard coal', DataTypes.REAL_VALUED, InputTypes.OBSERVED_INPUT),\n",
    "    ('generation fossil oil', DataTypes.REAL_VALUED, InputTypes.OBSERVED_INPUT),\n",
    "    ('generation fossil oil shale', DataTypes.REAL_VALUED, InputTypes.OBSERVED_INPUT),\n",
    "    ('generation fossil peat', DataTypes.REAL_VALUED, InputTypes.OBSERVED_INPUT),\n",
    "    ('generation geothermal', DataTypes.REAL_VALUED, InputTypes.OBSERVED_INPUT),\n",
    "    ('generation hydro pumped storage consumption', DataTypes.REAL_VALUED, InputTypes.OBSERVED_INPUT),\n",
    "    ('generation hydro run-of-river and poundage', DataTypes.REAL_VALUED, InputTypes.OBSERVED_INPUT),\n",
    "    ('generation hydro water reservoir', DataTypes.REAL_VALUED, InputTypes.OBSERVED_INPUT),\n",
    "    ('generation marine', DataTypes.REAL_VALUED, InputTypes.OBSERVED_INPUT),\n",
    "    ('generation nuclear', DataTypes.REAL_VALUED, InputTypes.OBSERVED_INPUT),\n",
    "    ('generation other', DataTypes.REAL_VALUED, InputTypes.OBSERVED_INPUT),\n",
    "    ('generation other renewable', DataTypes.REAL_VALUED, InputTypes.OBSERVED_INPUT),\n",
    "    ('generation solar', DataTypes.REAL_VALUED, InputTypes.OBSERVED_INPUT),\n",
    "    ('generation waste', DataTypes.REAL_VALUED, InputTypes.OBSERVED_INPUT),\n",
    "    ('generation wind offshore', DataTypes.REAL_VALUED, InputTypes.OBSERVED_INPUT),\n",
    "    ('generation wind onshore', DataTypes.REAL_VALUED, InputTypes.OBSERVED_INPUT),\n",
    "\n",
    "    # --- Observed categorical ---\n",
    "    ('weather_main', DataTypes.CATEGORICAL, InputTypes.OBSERVED_INPUT),\n",
    "    ('weather_description_simplified', DataTypes.CATEGORICAL, InputTypes.OBSERVED_INPUT),]\n",
    "\n",
    "        use_tlf = bool(getattr(self.hparams, \"use_tlf\", True))\n",
    "        replace = bool(getattr(self.hparams, \"tlf_replace_with_seasonal\", False))\n",
    "         # Relevant indices for TFT\n",
    "        #Collect global indices of real-valued and categorical columns\n",
    "        _real_cols = [i for i, (_, dt, _) in enumerate(self.column_definition) if dt == DataTypes.REAL_VALUED]\n",
    "        _cat_cols  = [i for i, (_, dt, _) in enumerate(self.column_definition) if dt == DataTypes.CATEGORICAL]\n",
    "\n",
    "        #Collect global indices by role (from the full column_definition)\n",
    "        _obs_glob        = [i for i, (_, dt, rl) in enumerate(self.column_definition)\n",
    "                    if rl == InputTypes.OBSERVED_INPUT and dt == DataTypes.REAL_VALUED]\n",
    "        _known_reg_glob  = [i for i, (_, dt, rl) in enumerate(self.column_definition)\n",
    "                    if rl == InputTypes.KNOWN_INPUT    and dt == DataTypes.REAL_VALUED]\n",
    "        _known_cat_glob  = [i for i, (_, dt, rl) in enumerate(self.column_definition)\n",
    "                    if rl == InputTypes.KNOWN_INPUT    and dt == DataTypes.CATEGORICAL]\n",
    "        _static_reg_glob = [i for i, (_, dt, rl) in enumerate(self.column_definition)\n",
    "                    if rl == InputTypes.STATIC_INPUT   and dt == DataTypes.REAL_VALUED]  # may be empty\n",
    "\n",
    "         # Map global indices → local indices within the model’s stacked tensors\n",
    "        #    (TFT expects indices relative to the real/categorical stacks, not global column_definition indices)\n",
    "        # --- DEBUG: peek column_definition & parsed roles/dtypes ---\n",
    "    \n",
    "        self._input_obs_loc               = [ _real_cols.index(i) for i in _obs_glob ]\n",
    "        self._known_regular_input_idx     = [ _real_cols.index(i) for i in _known_reg_glob ]\n",
    "        self._known_categorical_input_idx = [ _cat_cols.index(i)  for i in _known_cat_glob ]\n",
    "        self._static_input_loc            = [ _real_cols.index(i) for i in _static_reg_glob ] # [] if no static real inputs\n",
    "        setattr(self.hparams, \"input_obs_loc\",            list(self._input_obs_loc))\n",
    "        setattr(self.hparams, \"known_regular_inputs\",     list(self._known_regular_input_idx))\n",
    "        setattr(self.hparams, \"known_categorical_inputs\", list(self._known_categorical_input_idx))\n",
    "        setattr(self.hparams, \"static_input_loc\",         list(self._static_input_loc))\n",
    "      \n",
    "       \n",
    "        if not use_tlf and not replace:\n",
    "    # E1: drop TLF\n",
    "            self.column_definition = [\n",
    "        t for t in self.column_definition\n",
    "        if not (t[0] == \"total load forecast\" and t[2] == InputTypes.KNOWN_INPUT)\n",
    "           ]\n",
    "        elif replace:\n",
    "    # E2: replace TLF with seasonal_baselin\n",
    "            new = []\n",
    "            for name, dt, role in self.column_definition:\n",
    "                if name == \"total load forecast\" and role == InputTypes.KNOWN_INPUT:\n",
    "                    new.append((\"seasonal_baseline\", dt, role))\n",
    "                else:\n",
    "                    new.append((name, dt, role))\n",
    "            self.column_definition = new\n",
    "\n",
    "        self._refresh_input_names_and_counts()\n",
    "        self.hparams.num_non_static_historical_inputs = self.num_non_static_historical_inputs\n",
    "        self.hparams.num_non_static_future_inputs     = self.num_non_static_future_inputs\n",
    "\n",
    "        # Network params\n",
    "        self.quantiles = [0.1, 0.5, 0.9]\n",
    "#         self.use_cudnn = use_cudnn  # Whether to use GPU optimised LSTM\n",
    "        self.hidden_layer_size = int(hparams.hidden_layer_size)#int(params['hidden_layer_size'])\n",
    "        self.dropout_rate = float(hparams.dropout_rate)#float(params['dropout_rate'])\n",
    "        self.max_gradient_norm = float(hparams.max_gradient_norm)#float(params['max_gradient_norm'])\n",
    "        self.learning_rate = float(hparams.learning_rate)#float(params['learning_rate'])\n",
    "        self.minibatch_size = int(hparams.minibatch_size)#int(params['minibatch_size'])\n",
    "        self.num_epochs = int(hparams.num_epochs)#int(params['num_epochs'])\n",
    "        self.early_stopping_patience = int(hparams.early_stopping_patience)#int(params['early_stopping_patience'])\n",
    "        self.weight_decay=int(hparams.weight_decay)\n",
    "\n",
    "        self.num_encoder_steps = int(hparams.num_encoder_steps)#int(params['num_encoder_steps'])\n",
    "        self.num_stacks = int(hparams.stack_size)#int(params['stack_size'])\n",
    "        self.num_heads = int(hparams.num_heads)#int(params['num_heads'])\n",
    "        self.hist_var_proj = torch.nn.Parameter(\n",
    "    torch.empty(self.num_non_static_historical_inputs, self.hidden_layer_size)\n",
    "    )\n",
    "        self.fut_var_proj  = torch.nn.Parameter(\n",
    "    torch.empty(self.num_non_static_future_inputs,     self.hidden_layer_size)\n",
    "     )\n",
    "        torch.nn.init.xavier_uniform_(self.hist_var_proj)\n",
    "        torch.nn.init.xavier_uniform_(self.fut_var_proj)\n",
    "        \n",
    "        # Extra components to store Tensorflow nodes for attention computations\n",
    "        self._input_placeholder = None\n",
    "        self._attention_components = None\n",
    "        self._prediction_parts = None\n",
    "\n",
    "        print('*** {} params ***'.format(self.name))\n",
    "        for k in vars(hparams):\n",
    "            print('# {} = {}'.format(k, vars(hparams)[k]))\n",
    "            \n",
    "        self.train_criterion = QuantileLossCalculator(self.quantiles, self.output_size)\n",
    "        self.test_criterion = NormalizedQuantileLossCalculator(self.quantiles, self.output_size)\n",
    "\n",
    "        # Build model\n",
    "        ## Build embeddings\n",
    "        self.build_embeddings()\n",
    "        \n",
    "        ## Build Static Contex Networks\n",
    "        self.build_static_context_networks()\n",
    "        \n",
    "        ## Building Variable Selection Networks\n",
    "        self.build_variable_selection_networks()\n",
    "        \n",
    "        ## Build Lstm\n",
    "        self.build_lstm()\n",
    "        \n",
    "        ## Build GLU for after lstm encoder decoder and layernorm\n",
    "        self.build_post_lstm_gate_add_norm()\n",
    "        \n",
    "        ## Build Static Enrichment Layer\n",
    "        self.build_static_enrichment()\n",
    "        \n",
    "        ## Building decoder multihead attention\n",
    "        self.build_temporal_self_attention()\n",
    "        \n",
    "        ## Building positionwise decoder\n",
    "        self.build_position_wise_feed_forward()\n",
    "        \n",
    "        ## Build output feed forward\n",
    "        self.build_output_feed_forward()\n",
    "        ##record KNOWN real-valued variable names in order \n",
    "        self.known_real_names = [name for (name, dtype, role) in self.column_definition if role == InputTypes.KNOWN_INPUT and dtype == DataTypes.REAL_VALUED]\n",
    "        self.name2idx_known = {n: i for i, n in enumerate(self.known_real_names)}\n",
    "        ## Initializing remaining weights\n",
    "        self.init_weights()\n",
    "        print(\"training_step exists:\", hasattr(self, \"training_step\"))\n",
    "        print(\"[CHK] final input_obs_loc =\", self._input_obs_loc)\n",
    "        self._gf_every = 50  # accumulate every N steps; change as you like\n",
    "        self._gf_layers = [n for n, p in self.named_parameters()\n",
    "                           if p.requires_grad and (\"bias\" not in n)]\n",
    "        self._gf_index  = {name: i for i, name in enumerate(self._gf_layers)}\n",
    "        n = len(self._gf_layers)\n",
    "        self._gf_sum    = np.zeros(n, dtype=np.float64)  # sum of mean|grad|\n",
    "        self._gf_count  = np.zeros(n, dtype=np.int64)    # how many times each layer got updated\n",
    "        self._gf_steps  = 0\n",
    "\n",
    "\n",
    "        \n",
    "    def init_weights(self):\n",
    "        for name, p in self.named_parameters():\n",
    "            if ('lstm' in name and 'ih' in name) and 'bias' not in name:\n",
    "                #print(name)\n",
    "                #print(p.shape)\n",
    "                torch.nn.init.xavier_uniform_(p)\n",
    "#                 torch.nn.init.kaiming_normal_(p, a=0, mode='fan_in', nonlinearity='sigmoid')\n",
    "            elif ('lstm' in name and 'hh' in name) and 'bias' not in name:\n",
    "        \n",
    "                 torch.nn.init.orthogonal_(p)\n",
    "            \n",
    "            elif 'lstm' in name and 'bias' in name:\n",
    "                #print(name)\n",
    "                #print(p.shape)\n",
    "                torch.nn.init.zeros_(p)\n",
    "    def _refresh_input_names_and_counts(self):\n",
    "        self.known_real_names = [\n",
    "        n for (n, dt, role) in self.column_definition\n",
    "        if role == InputTypes.KNOWN_INPUT and dt == DataTypes.REAL_VALUED\n",
    "    ]\n",
    "        self.observed_real_names = [\n",
    "        n for (n, dt, role) in self.column_definition\n",
    "        if role == InputTypes.OBSERVED_INPUT and dt == DataTypes.REAL_VALUED\n",
    "      ]\n",
    "\n",
    "    # encoder (history) = observed + known; decoder (future) = known only\n",
    "        self.hist_real_names = self.observed_real_names + self.known_real_names\n",
    "        self.fut_real_names  = self.known_real_names\n",
    "\n",
    "    # counts expected by later assertions / projections\n",
    "        self.num_non_static_historical_inputs = len(self.hist_real_names)\n",
    "        self.num_non_static_future_inputs     = len(self.fut_real_names)\n",
    "\n",
    "    # handy map for TLF dropout / plots, etc.\n",
    "        self.name2idx_known = {n: i for i, n in enumerate(self.known_real_names)}\n",
    "\n",
    "        \n",
    "    def get_historical_num_inputs(self):\n",
    "        \n",
    "        obs_inputs = [i for i in self._input_obs_loc]\n",
    "        \n",
    "        known_regular_inputs = [i for i in self._known_regular_input_idx\n",
    "                                if i not in self._static_input_loc]\n",
    "            \n",
    "        known_categorical_inputs = [i for i in self._known_categorical_input_idx\n",
    "                                    if i + self.num_regular_variables not in self._static_input_loc]\n",
    "        \n",
    "        wired_embeddings = [i for i in range(self.num_categorical_variables)\n",
    "                            if i not in self._known_categorical_input_idx \n",
    "                            and i not in self._input_obs_loc]\n",
    "\n",
    "        unknown_inputs = [i for i in range(self.num_regular_variables)\n",
    "                          if i not in self._known_regular_input_idx\n",
    "                          and i not in self._input_obs_loc]\n",
    "\n",
    "        return len(obs_inputs+known_regular_inputs+known_categorical_inputs+wired_embeddings+unknown_inputs)\n",
    "    \n",
    "    def get_future_num_inputs(self):\n",
    "            \n",
    "        known_regular_inputs = [i for i in self._known_regular_input_idx\n",
    "                                if i not in self._static_input_loc]\n",
    "            \n",
    "        known_categorical_inputs = [i for i in self._known_categorical_input_idx\n",
    "                                    if i + self.num_regular_variables not in self._static_input_loc]\n",
    "\n",
    "        return len(known_regular_inputs + known_categorical_inputs)\n",
    "    \n",
    "    def build_embeddings(self):\n",
    "        self.categorical_var_embeddings = nn.ModuleList([nn.Embedding(self.category_counts[i], \n",
    "                                                                      self.hidden_layer_size) \n",
    "                                                     for i in range(self.num_categorical_variables)])\n",
    "\n",
    "        self.regular_var_embeddings = nn.ModuleList([nn.Linear(1, \n",
    "                                                              self.hidden_layer_size) \n",
    "                                                  for i in range(self.num_regular_variables)])\n",
    "\n",
    "    def build_variable_selection_networks(self):\n",
    "        \n",
    "        self.static_vsn = VariableSelectionNetwork(hidden_layer_size = self.hidden_layer_size,\n",
    "                                                   input_size = self.hidden_layer_size * len(self._static_input_loc),\n",
    "                                                   output_size = len(self._static_input_loc),\n",
    "                                                   dropout_rate = self.dropout_rate)\n",
    "        \n",
    "        self.temporal_historical_vsn = VariableSelectionNetwork(hidden_layer_size = self.hidden_layer_size,\n",
    "                                                                input_size = self.hidden_layer_size *\n",
    "                                                                        self.num_non_static_historical_inputs,\n",
    "                                                                output_size = self.num_non_static_historical_inputs,\n",
    "                                                                dropout_rate = self.dropout_rate,\n",
    "                                                                additional_context=self.hidden_layer_size)\n",
    "        \n",
    "        self.temporal_future_vsn = VariableSelectionNetwork(hidden_layer_size = self.hidden_layer_size,\n",
    "                                                            input_size = self.hidden_layer_size *\n",
    "                                                                        self.num_non_static_future_inputs,\n",
    "                                                            output_size = self.num_non_static_future_inputs,\n",
    "                                                            dropout_rate = self.dropout_rate,\n",
    "                                                            additional_context=self.hidden_layer_size)\n",
    "        \n",
    "    def build_static_context_networks(self):\n",
    "        \n",
    "        self.static_context_variable_selection_grn = GatedResidualNetwork(self.hidden_layer_size,\n",
    "                                                                          dropout_rate=self.dropout_rate)\n",
    "        \n",
    "        self.static_context_enrichment_grn = GatedResidualNetwork(self.hidden_layer_size,\n",
    "                                                              dropout_rate=self.dropout_rate)\n",
    "\n",
    "        self.static_context_state_h_grn = GatedResidualNetwork(self.hidden_layer_size,\n",
    "                                                           dropout_rate=self.dropout_rate)\n",
    "        \n",
    "        self.static_context_state_c_grn = GatedResidualNetwork(self.hidden_layer_size,\n",
    "                                                           dropout_rate=self.dropout_rate)\n",
    "        \n",
    "    def build_lstm(self):\n",
    "        self.historical_lstm = nn.LSTM(input_size = self.hidden_layer_size,\n",
    "                                       hidden_size = self.hidden_layer_size,\n",
    "                                       batch_first = True)\n",
    "        self.future_lstm = nn.LSTM(input_size = self.hidden_layer_size,\n",
    "                                   hidden_size = self.hidden_layer_size,\n",
    "                                   batch_first = True)\n",
    "        \n",
    "    def build_post_lstm_gate_add_norm(self):\n",
    "        self.post_seq_encoder_gate_add_norm = GateAddNormNetwork(self.hidden_layer_size,\n",
    "                                                                 self.hidden_layer_size,\n",
    "                                                                 self.dropout_rate,\n",
    "                                                                 activation = None)\n",
    "        \n",
    "    def build_static_enrichment(self):\n",
    "        self.static_enrichment = GatedResidualNetwork(self.hidden_layer_size,\n",
    "                                                      dropout_rate = self.dropout_rate,\n",
    "                                                      additional_context=self.hidden_layer_size)\n",
    "        \n",
    "    def build_temporal_self_attention(self):\n",
    "        self.self_attn_layer = InterpretableMultiHeadAttention(n_head = self.num_heads, \n",
    "                                                               d_model = self.hidden_layer_size,\n",
    "                                                               dropout = self.dropout_rate)\n",
    "        \n",
    "        self.post_attn_gate_add_norm = GateAddNormNetwork(self.hidden_layer_size,\n",
    "                                                           self.hidden_layer_size,\n",
    "                                                           self.dropout_rate,\n",
    "                                                           activation = None)\n",
    "        \n",
    "    def build_position_wise_feed_forward(self):\n",
    "        self.GRN_positionwise = GatedResidualNetwork(self.hidden_layer_size,\n",
    "                                                     dropout_rate = self.dropout_rate)\n",
    "        \n",
    "        self.post_tfd_gate_add_norm = GateAddNormNetwork(self.hidden_layer_size,\n",
    "                                                         self.hidden_layer_size,\n",
    "                                                         self.dropout_rate,\n",
    "                                                         activation = None)\n",
    "        \n",
    "    def build_output_feed_forward(self):\n",
    "        self.output_feed_forward = torch.nn.Linear(self.hidden_layer_size, \n",
    "                                                   self.output_size * len(self.quantiles))\n",
    "    def get_decoder_mask(self, x, enc_len=None, as_bool=True):\n",
    " \n",
    "        B, T = x.size(0), x.size(1)\n",
    "        enc_len = self.hparams.num_encoder_steps if enc_len is None else int(enc_len)\n",
    "\n",
    "    # future positions are masked (upper triangle)\n",
    "    # True = mask out ; False = keep\n",
    "        future_mask = torch.triu(torch.ones(T, T, device=x.device, dtype=torch.bool), diagonal=1)\n",
    "\n",
    "    # Broadcast to batch: [B, T, T]\n",
    "        mask_bool = future_mask.unsqueeze(0).expand(B, -1, -1).contiguous()\n",
    "\n",
    "        if as_bool:\n",
    "            return mask_bool  # bool mask: True means \"do not attend\"\n",
    "        else:\n",
    "         # additive mask: 0 for keep, -inf for mask\n",
    "            zero = torch.tensor(0.0, device=x.device, dtype=x.dtype)\n",
    "            neginf = torch.tensor(float(\"-inf\"), device=x.device, dtype=x.dtype)\n",
    "            return torch.where(mask_bool, neginf, zero)\n",
    "    def mask_decoder_observed_(self, x_observed):\n",
    "        if x_observed is None:\n",
    "            return x_observed\n",
    "        nd = int(self.hparams.total_time_steps - self.hparams.num_encoder_steps)\n",
    "        if nd > 0:\n",
    "            x_observed[:, -nd:, :] = 0.0\n",
    "        return x_observed\n",
    "\n",
    "    def mask_decoder_observed_cat_(self, x_obs_cat, pad_idx=0):\n",
    "        if x_obs_cat is None:\n",
    "            return x_obs_cat\n",
    "        nd = int(self.hparams.total_time_steps - self.hparams.num_encoder_steps)\n",
    "        if nd > 0:\n",
    "            x_obs_cat[:, -nd:, :] = pad_idx\n",
    "        return x_obs_cat\n",
    "\n",
    "    \n",
    "    def get_tft_embeddings(self, regular_inputs, categorical_inputs):\n",
    "   \n",
    "        B, T, Nr = regular_inputs.shape\n",
    "        Nc = 0 if (categorical_inputs is None) else categorical_inputs.shape[-1]\n",
    "        \n",
    "\n",
    "   \n",
    "        assert Nr == self.num_regular_variables, \"regular_inputs dim mismatch\"\n",
    "        assert (Nc == self.num_categorical_variables) or (categorical_inputs is None), \"categorical_inputs dim mismatch\"\n",
    "\n",
    "        has_cate = (categorical_inputs is not None) and (Nc > 0)\n",
    "\n",
    "    # -------- helpers: split combined indices into regular / categorical local indices --------\n",
    "        def split_combined_indices(idxs_combined):\n",
    "            reg = set()\n",
    "            cat = set()\n",
    "            for j in idxs_combined:\n",
    "                if j < self.num_regular_variables:\n",
    "                    reg.add(j)  # local = combined\n",
    "                else:\n",
    "                # local index inside categorical block\n",
    "                    cat_local = j - self.num_regular_variables\n",
    "                    if has_cate and 0 <= cat_local < Nc:\n",
    "                        cat.add(cat_local)\n",
    "            return reg, cat\n",
    "\n",
    "    # turn to sets for fast lookup\n",
    "        static_combined = set(getattr(self, \"_static_input_loc\", []) or [])\n",
    "        input_obs_combined = set(getattr(self, \"_input_obs_loc\", []) or [])\n",
    "        known_reg_set = set(getattr(self, \"_known_regular_input_idx\", []) or [])\n",
    "        known_cat_set = set(getattr(self, \"_known_categorical_input_idx\", []) or [])\n",
    "\n",
    "        static_reg_idx, static_cat_idx = split_combined_indices(static_combined)\n",
    "        obs_reg_idx,   obs_cat_idx   = split_combined_indices(input_obs_combined)\n",
    "    \n",
    "    # -------- Static inputs (optional) --------\n",
    "        if static_reg_idx or static_cat_idx:\n",
    "            static_regular_inputs = [\n",
    "            self.regular_var_embeddings[i](regular_inputs[:, 0, i:i+1]) for i in sorted(static_reg_idx)\n",
    "        ]  # each: (B, 1, H)\n",
    "            static_categorical_inputs = []\n",
    "            if has_cate and static_cat_idx:\n",
    "                for i in sorted(static_cat_idx):  # local idx in categorical space\n",
    "                    emb = self.categorical_var_embeddings[i](categorical_inputs[:, 0, i])  # (B, H)\n",
    "                    static_categorical_inputs.append(emb.unsqueeze(1))  # -> (B,1,H)\n",
    "            if static_regular_inputs or static_categorical_inputs:\n",
    "                static_inputs = torch.cat(static_regular_inputs + static_categorical_inputs, dim=1)  # (B, S, H)\n",
    "            else:\n",
    "                static_inputs = None\n",
    "        else:\n",
    "            static_inputs = None\n",
    "\n",
    "    # -------- Observed inputs (historical only block, we just build representation here) --------\n",
    "        obs_parts = []\n",
    "        if obs_reg_idx:\n",
    "            obs_reg = torch.stack(\n",
    "            [self.regular_var_embeddings[i](regular_inputs[..., i:i+1]) for i in sorted(obs_reg_idx)],\n",
    "            dim=-1\n",
    "             )  # (B,T,H, n_obs_reg)\n",
    "            obs_parts.append(obs_reg)\n",
    "        if has_cate and obs_cat_idx:\n",
    "            obs_cat = torch.stack(\n",
    "            [self.categorical_var_embeddings[i](categorical_inputs[..., i]) for i in sorted(obs_cat_idx)],\n",
    "            dim=-1\n",
    "            )  # (B,T,H, n_obs_cat)\n",
    "            obs_parts.append(obs_cat)\n",
    "\n",
    "        if obs_parts:\n",
    "            obs_inputs = torch.cat(obs_parts, dim=-1)  # (B,T,H, n_obs_total)\n",
    "        else:\n",
    "            obs_inputs = torch.empty(B, T, self.hidden_layer_size, 0, device=regular_inputs.device)\n",
    "\n",
    "    # -------- Unknown inputs (a priori unknown at prediction time) --------\n",
    "    # regular unknown = not known & not observed\n",
    "        unknown_reg_idx = [i for i in range(Nr) if (i not in known_reg_set and i not in obs_reg_idx and i not in static_reg_idx)]\n",
    "        unknown_cat_idx = []\n",
    "        if has_cate:\n",
    "            unknown_cat_idx = [i for i in range(Nc)\n",
    "                           if (i not in known_cat_set and i not in obs_cat_idx and i not in static_cat_idx)]\n",
    "\n",
    "            unk_parts = []\n",
    "        if unknown_reg_idx:\n",
    "            unk_reg = torch.stack(\n",
    "            [self.regular_var_embeddings[i](regular_inputs[..., i:i+1]) for i in unknown_reg_idx],\n",
    "            dim=-1\n",
    "           )  # (B,T,H, n_unk_reg)\n",
    "            unk_parts.append(unk_reg)\n",
    "        if has_cate and unknown_cat_idx:\n",
    "            unk_cat = torch.stack(\n",
    "            [self.categorical_var_embeddings[i](categorical_inputs[..., i]) for i in unknown_cat_idx],\n",
    "            dim=-1\n",
    "        )  # (B,T,H, n_unk_cat)\n",
    "            unk_parts.append(unk_cat)\n",
    "\n",
    "        if unk_parts:\n",
    "            unknown_inputs = torch.cat(unk_parts, dim=-1)  # (B,T,H, n_unk_total)\n",
    "        else:\n",
    "            unknown_inputs = None\n",
    "\n",
    "\n",
    "        known_parts = []\n",
    "        if known_reg_set:\n",
    "            known_reg = torch.stack(\n",
    "            [self.regular_var_embeddings[i](regular_inputs[..., i:i+1]) for i in sorted(known_reg_set)],\n",
    "            dim=-1\n",
    "           )  # (B,T,H, n_known_reg)\n",
    "            known_parts.append(known_reg)\n",
    "\n",
    "        if has_cate and known_cat_set:\n",
    "            known_cat = torch.stack(\n",
    "            [self.categorical_var_embeddings[i](categorical_inputs[..., i]) for i in sorted(known_cat_set)],\n",
    "            dim=-1\n",
    "           )  # (B,T,H, n_known_cat)\n",
    "            known_parts.append(known_cat)\n",
    "\n",
    "        if known_parts:\n",
    "            known_combined_layer = torch.cat(known_parts, dim=-1)  # (B,T,H, n_known_total)\n",
    "        else:\n",
    "            known_combined_layer = torch.empty(B, T, self.hidden_layer_size, 0, device=regular_inputs.device)\n",
    "\n",
    "        return unknown_inputs, known_combined_layer, obs_inputs, static_inputs\n",
    "\n",
    "        \n",
    "    def forward(self, all_inputs):\n",
    "        if not isinstance(all_inputs, (list, tuple)) or len(all_inputs) < 3:\n",
    "            raise ValueError(f\"forward expects (hist_regular, fut_regular, x_static[, hist_cate, fut_cate]), got {type(all_inputs)} len={len(all_inputs) if isinstance(all_inputs,(list,tuple)) else 'n/a'}\")\n",
    "\n",
    "        if len(all_inputs) >= 5:\n",
    "            hist_regular, fut_regular, x_static, hist_cate, fut_cate = all_inputs[:5]\n",
    "        else:\n",
    "            hist_regular, fut_regular, x_static = all_inputs[:3]\n",
    "            hist_cate = fut_cate = None\n",
    "\n",
    "        device = hist_regular.device  # ensure all tensors move to the same device\n",
    "        hist_regular = hist_regular.to(device).float()\n",
    "        fut_regular  = fut_regular.to(device).float()\n",
    "        # Cast/allocate x_static on the correct device\n",
    "        x_static = (\n",
    "    x_static.to(device).float()\n",
    "    if x_static is not None\n",
    "    else torch.zeros(hist_regular.size(0), 0, device=device)\n",
    "     )\n",
    "\n",
    "# Move categorical tensors to the same device/dtype\n",
    "        if hist_cate is not None:\n",
    "            hist_cate = hist_cate.to(device).long()\n",
    "        if fut_cate is not None:\n",
    "            fut_cate = fut_cate.to(device).long()\n",
    "\n",
    "# Read config values\n",
    "        enc_cfg = int(getattr(self.hparams, \"num_encoder_steps\", getattr(self, \"num_encoder_steps\")))\n",
    "        total_cfg = int(getattr(self.hparams, \"total_time_steps\", getattr(self, \"time_steps\")))\n",
    "        dec_cfg = total_cfg - enc_cfg\n",
    "        H = int(getattr(self.hparams, \"hidden_layer_size\", getattr(self, \"hidden_layer_size\")))\n",
    "                \n",
    "# --- lazily project static features to hidden size H if needed ---\n",
    "# Guard against empty static vectors (B, 0) to avoid in_features=0 errors.\n",
    "        if (x_static is not None) and (x_static.dim() == 2) and (x_static.size(-1) > 0) and (x_static.size(-1) != H):\n",
    "            if not hasattr(self, \"static_proj\"):\n",
    "                self.static_proj = torch.nn.Linear(x_static.size(-1), H).to(device)\n",
    "            x_static = self.static_proj(x_static)  # -> [B, H]\n",
    "\n",
    "# Shapes, sanity checks\n",
    "        B, enc, Nr_hist = hist_regular.shape\n",
    "        _,  dec, Nr_fut = fut_regular.shape\n",
    "# device = hist_regular.device  # (already set above)\n",
    "        assert enc == enc_cfg, f\"enc mismatch: got {enc}, expect {enc_cfg}\"\n",
    "        assert enc + dec == total_cfg, f\"time len mismatch: enc({enc}) + dec({dec}) != total({total_cfg})\"\n",
    "\n",
    "# Decide whether static branch is enabled\n",
    "        use_static_branch = (\n",
    "    (x_static is not None)\n",
    "    and (x_static.dim() == 2)\n",
    "    and (x_static.shape[-1] == H)\n",
    "    and (getattr(self, \"static_vsn\", None) is not None)\n",
    ")\n",
    "\n",
    "        if use_static_branch:\n",
    "            static_encoder, sparse_weights = self.static_vsn(x_static)\n",
    "            static_context_variable_selection = self.static_context_variable_selection_grn(static_encoder)\n",
    "            static_context_enrichment        = self.static_context_enrichment_grn(static_encoder)\n",
    "            static_context_state_h           = self.static_context_state_h_grn(static_encoder)\n",
    "            static_context_state_c           = self.static_context_state_c_grn(static_encoder)\n",
    "        else:\n",
    "            if (x_static is not None) and (x_static.numel() > 0) and (x_static.shape[-1] != H):\n",
    "                print(f\"[WARN] x_static has dim {x_static.shape[-1]} != H({H}); bypassing static_vsn.\")\n",
    "            sparse_weights = None\n",
    "            static_encoder                     = torch.zeros(B, H, device=device)\n",
    "            static_context_variable_selection  = torch.zeros(B, H, device=device)\n",
    "            static_context_enrichment          = torch.zeros(B, H, device=device)\n",
    "            static_context_state_h             = torch.zeros(B, H, device=device)\n",
    "            static_context_state_c             = torch.zeros(B, H, device=device)\n",
    "\n",
    "        hist_emb = torch.einsum('btn,nh->bthn', hist_regular, self.hist_var_proj)  # [B, T, H, N_hist]\n",
    "        fut_emb  = torch.einsum('btn,nh->bthn', fut_regular,  self.fut_var_proj)   # [B, T, H, N_fut]\n",
    "        historical_features, historical_flags = self.temporal_historical_vsn(\n",
    "        (hist_emb, static_context_variable_selection)   \n",
    "       )  # -> [B, enc, H]\n",
    "        future_features, future_flags = self.temporal_future_vsn(\n",
    "        (fut_emb, static_context_variable_selection)\n",
    "        )  # -> [B, dec, H]\n",
    "\n",
    "        history_lstm, (state_h, state_c) = self.historical_lstm(\n",
    "        historical_features,\n",
    "        (static_context_state_h.unsqueeze(0), static_context_state_c.unsqueeze(0))\n",
    "         )  # [B, enc, H]\n",
    "        future_lstm, _ = self.future_lstm(future_features, (state_h, state_c))  # [B, dec, H]\n",
    "\n",
    "    # Skip with original inputs after VSN\n",
    "        input_embeddings = torch.cat((historical_features, future_features), dim=1)  # [B, total, H]\n",
    "        lstm_layer       = torch.cat((history_lstm,      future_lstm),      dim=1)  # [B, total, H]\n",
    "\n",
    "        temporal_feature_layer = self.post_seq_encoder_gate_add_norm(lstm_layer, input_embeddings)  # [B, total, H]\n",
    "\n",
    "        expanded_static_context = static_context_enrichment.unsqueeze(1)  # [B,1,H]\n",
    "        enriched = self.static_enrichment((temporal_feature_layer, expanded_static_context))       # [B, total, H]\n",
    "        x, self_att = self.self_attn_layer(\n",
    "        enriched, enriched, enriched,\n",
    "        mask=self.get_decoder_mask(enriched)  \n",
    "          )  # x: [B, total, H]\n",
    "        x = self.post_attn_gate_add_norm(x, enriched)\n",
    "\n",
    "        decoder = self.GRN_positionwise(x)  # [B, total, H]\n",
    "        transformer_layer = self.post_tfd_gate_add_norm(decoder, temporal_feature_layer)  # [B, total, H]\n",
    "        outputs = self.output_feed_forward(transformer_layer[:, enc:, :])  # [B, dec, out_size]\n",
    "        return outputs\n",
    "       \n",
    "    def loss(self, y_hat, y):\n",
    "        return self.train_criterion.apply(y_hat, y_true)\n",
    "    \n",
    "    def test_loss(self, y_hat, y):\n",
    "        q = self.quantiles[1] if q is None else q\n",
    "        return self.test_criterion.apply(y_true, y_hat, q)\n",
    "        \n",
    "    def _prepare_tft_inputs(self, batch):\n",
    "\n",
    "        enc   = getattr(self, \"num_encoder_steps\", None) or getattr(self.hparams, \"num_encoder_steps\", None)\n",
    "        total = getattr(self, \"time_steps\", None) or getattr(self, \"total_time_steps\", None) or getattr(self.hparams, \"total_time_steps\", None)\n",
    "\n",
    "        if isinstance(batch[0], (list, tuple)):\n",
    "            xb = batch[0]\n",
    "            if len(xb) == 4:\n",
    "            # (x_known, x_observed, x_static, x_categorical)\n",
    "                x_known, x_observed, x_static, x_categorical = xb\n",
    "            elif len(xb) == 3:\n",
    "                x_known, x_observed, x_categorical = xb\n",
    "                x_static = None                     \n",
    "            else:\n",
    "                raise ValueError(f\"Unexpected input tuple length: {len(xb)}\")\n",
    "            y = batch[1]\n",
    "        else:\n",
    "            raise ValueError(\"Batch format not supported; expected ((x_known, x_observed, x_static[, x_categorical]), y)\")\n",
    "        def _squeeze_TK(x):\n",
    "            if x is None:\n",
    "                return None\n",
    "            return x.squeeze(-1) if (x.dim() == 4 and x.size(-1) == 1) else x\n",
    "\n",
    "\n",
    "        # 1) normalize dtypes & memory layout\n",
    "        x_known       = _squeeze_TK(x_known).contiguous().float()\n",
    "        x_observed    = _squeeze_TK(x_observed).contiguous().float()\n",
    "        x_categorical = _squeeze_TK(x_categorical)\n",
    "        if x_categorical is not None:\n",
    "            x_categorical = x_categorical.contiguous().long()\n",
    "        y = y.contiguous().float()\n",
    "        # === OPTIONAL: training-time feature dropout on TLF ===\n",
    "        p = float(getattr(self.hparams, \"tlf_dropout_p\", 0.0) or 0.0)\n",
    "        if self.training and p > 0.0 and \"total load forecast\" in self.name2idx_known:\n",
    "            tlf_idx = self.name2idx_known[\"total load forecast\"]\n",
    "        # mask shape: [B, T, 1] \n",
    "            mask = (torch.rand(x_known.size(0), x_known.size(1), 1, device=x_known.device) < p)\n",
    "            col = x_known[..., tlf_idx:tlf_idx+1]\n",
    "            mu  = col.mean()\n",
    "            x_known[..., tlf_idx:tlf_idx+1] = torch.where(mask, mu, col)\n",
    "\n",
    "        # read window config online from hparams (never use stale cached attrs)\n",
    "        total = int(self.time_steps)      \n",
    "        enc   = int(self.num_encoder_steps)     \n",
    "        dec   = total - enc\n",
    "        assert 0 < enc < total, f\"invalid windows: enc={enc}, total={total}\"\n",
    "\n",
    "        # align time length T to `total` by cropping the last `total` steps (if longer)\n",
    "        assert x_known.dim() == 3,    f\"x_known must be [B,T,K], got {x_known.shape}\"\n",
    "        assert x_observed.dim() == 3, f\"x_observed must be [B,T,K], got {x_observed.shape}\"\n",
    "        T = x_known.size(1)\n",
    "        assert x_observed.size(1) == T, f\"x_observed T {x_observed.size(1)} != x_known T {T}\"\n",
    "\n",
    "        if T != total:\n",
    "            if T > total:\n",
    "                s = T - total\n",
    "                x_known    = x_known[:, s:, :].contiguous()\n",
    "                x_observed = x_observed[:, s:, :].contiguous()\n",
    "                if x_categorical is not None and x_categorical.size(1) == T:\n",
    "                    x_categorical = x_categorical[:, s:, :].contiguous()\n",
    "        # if y carries a time axis of length T, crop it consistently\n",
    "                if y.dim() >= 2 and y.size(1) == T:\n",
    "                    y = y[:, s:, ...].contiguous()\n",
    "        # (optional) warn once\n",
    "                if not hasattr(self, \"_window_warned\"):\n",
    "                    print(f\"[TFT] Cropped input windows from T={T} to total={total} (enc={enc}, dec={dec}).\")\n",
    "                    self._window_warned = True\n",
    "            else:\n",
    "                raise AssertionError(\n",
    "            f\"dataset window too short: T={T} < total_time_steps={total}. \"\n",
    "            f\"Rebuild dataset with total={total} (enc={enc}, dec={dec}), \"\n",
    "            f\"or set hparams.total_time_steps={T}.\"\n",
    "        )\n",
    "\n",
    "        # split into historical/future parts\n",
    "        historical_inputs = torch.cat(\n",
    "    [x_known[:, :enc, :], x_observed[:, :enc, :]], dim=-1\n",
    ")       # [B, enc, K_hist]\n",
    "        future_inputs = x_known[:, enc:, :]               # [B, dec, K_fut]\n",
    "\n",
    "        # (optional) sanity checks\n",
    "        assert historical_inputs.size(1) == enc, f\"hist len {historical_inputs.size(1)} != enc {enc}\"\n",
    "        assert future_inputs.size(1)     == dec, f\"fut  len {future_inputs.size(1)} != dec {dec}\"\n",
    "\n",
    "        if x_categorical is not None and x_categorical.size(-1) > 0:\n",
    "            historical_categorical = x_categorical[:, :enc, :]\n",
    "            future_categorical     = x_categorical[:, enc:, :] if getattr(self, \"known_categorical_inputs\", []) else None\n",
    "        else:\n",
    "            historical_categorical = None\n",
    "            future_categorical     = None  \n",
    "\n",
    "        if x_static is None:\n",
    "            x_static_2d = torch.zeros(x_known.size(0), 0, device=x_known.device, dtype=x_known.dtype)\n",
    "        else:\n",
    "            x_static = x_static.float()\n",
    "            if x_static.dim() == 3:\n",
    "                with torch.no_grad():\n",
    "                    if x_static.size(1) > 1:\n",
    "                        diff = (x_static - x_static[:, :1, :]).abs().max().item()\n",
    "                        if diff > 1e-6:\n",
    "                            print(f\"[WARN] x_static varies over time (max diff={diff:.2e}); using first timestep.\")\n",
    "                x_static_2d = x_static[:, 0, :]\n",
    "            elif x_static.dim() == 2:\n",
    "                x_static_2d = x_static\n",
    "            else:\n",
    "                raise ValueError(f\"x_static must be [B,K] or [B,T,K], got {tuple(x_static.shape)}\")\n",
    "\n",
    "\n",
    "        if getattr(self, \"categorical_var_embeddings\", None) and (historical_categorical is not None):\n",
    "            all_inputs = (historical_inputs, future_inputs, x_static_2d, historical_categorical, future_categorical)\n",
    "        else:\n",
    "            all_inputs = (historical_inputs, future_inputs, x_static_2d)\n",
    "\n",
    "    \n",
    "        return all_inputs, y\n",
    "    def _align_targets_to_decoder(self, y, y_hat):\n",
    "        dec_len = self.time_steps - self.num_encoder_steps\n",
    "        assert dec_len > 0\n",
    "        if y.dim() == 2:            # [B, T] -> [B, T, 1]\n",
    "            y = y.unsqueeze(-1)\n",
    "        y_dec = y[:, -dec_len:, :] \n",
    "\n",
    "        if y_hat.size(-1) > 1 and y_dec.size(-1) == 1:\n",
    "            y_true = y_dec.expand(-1, -1, y_hat.size(-1))\n",
    "        else:\n",
    "            y_true = y_dec\n",
    "        assert y_true.shape == y_hat.shape, f\"y_true{y_true.shape} vs y_hat{y_hat.shape}\"\n",
    "        return y_true\n",
    "    def _runtime_sanity_checks(self, batch, stage=\"train\", strict=True):\n",
    "\n",
    "        (x_known, x_observed, x_static), y = batch\n",
    "\n",
    "\n",
    "        if getattr(self, \"_did_runtime_checks\", False):\n",
    "            return\n",
    "        self._did_runtime_checks = True\n",
    "\n",
    " \n",
    "        if x_observed is not None:\n",
    "            B, T, C_obs = x_observed.shape\n",
    "            assert C_obs == len(self._input_obs_loc), (\n",
    "            f\"[{stage}] Observed channels ({C_obs}) != len(input_obs_loc) ({len(self._input_obs_loc)}). \"\n",
    "            \"Check column_definition → mapping.\"\n",
    "        )\n",
    "\n",
    "   \n",
    "        n_real = getattr(self, \"_n_real_inputs\", None)\n",
    "        if n_real is not None:\n",
    "            bad = [i for i in self._input_obs_loc if not (0 <= i < n_real)]\n",
    "            assert not bad, f\"[{stage}] input_obs_loc has out-of-range indices: {bad} (n_real={n_real}).\"\n",
    "    \n",
    "            assert len(set(self._input_obs_loc)) == len(self._input_obs_loc), \\\n",
    "            f\"[{stage}] input_obs_loc contains duplicated indices: {self._input_obs_loc}\"\n",
    "\n",
    "   \n",
    "        if x_observed is not None:\n",
    "            nd = int(self.hparams.total_time_steps - self.hparams.num_encoder_steps)      \n",
    "        if nd > 0:\n",
    "            dec = slice(-nd, None)\n",
    "            leak_val = float(x_observed[:, dec].abs().sum().item())\n",
    "            assert leak_val == 0.0, f\"[{stage}] Observed not masked in decoder! leak={leak_val:.6f}.\"\n",
    "\n",
    "   \n",
    "        if x_observed is not None:\n",
    "            assert torch.isfinite(x_observed).all(), f\"[{stage}] x_observed has NaN/Inf.\"\n",
    "        if x_known is not None:\n",
    "            assert torch.isfinite(x_known).all(), f\"[{stage}] x_known has NaN/Inf.\"\n",
    "        \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # unpack according to your batch structure\n",
    "        (x_known, x_observed, x_static), y = batch\n",
    "        x_observed = self.mask_decoder_observed_(x_observed)\n",
    "        batch = (x_known, x_observed, x_static), y\n",
    "        attn_mask = self.get_decoder_mask(x_known, as_bool=True)\n",
    "        self._runtime_sanity_checks(batch, stage=\"train\")\n",
    "    \n",
    "        all_inputs, y = self._prepare_tft_inputs(batch)\n",
    "        y_hat = self(all_inputs)                               # [B, T_dec, Q]\n",
    "        y_true = self._align_targets_to_decoder(y, y_hat)      # [B, T_dec, Q]\n",
    "        loss = self.train_criterion.apply(y_hat, y_true)\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        (x_known, x_observed, x_static), y = batch\n",
    "        x_observed = self.mask_decoder_observed_(x_observed)\n",
    "        batch = (x_known, x_observed, x_static), y\n",
    "        self._runtime_sanity_checks(batch, stage=\"val\")\n",
    "        \n",
    "        all_inputs, y = self._prepare_tft_inputs(batch)\n",
    "        y_hat = self(all_inputs)\n",
    "        y_true = self._align_targets_to_decoder(y, y_hat)\n",
    "\n",
    "        if hasattr(self, \"test_criterion\"):\n",
    "            val_loss = self.test_criterion.apply(y_true, y_hat, self.quantiles[1]) \n",
    "        else:\n",
    "            val_loss = self.train_criterion.apply(y_hat, y_true) \n",
    "\n",
    "        self.log(\"val_loss\", val_loss, on_epoch=True, prog_bar=True)\n",
    "        if batch_idx == 0:  # only print onc\n",
    "            print(\"\\n[Inspect all_inputs]\")\n",
    "            print(\"Type:\", type(all_inputs))\n",
    "            if isinstance(all_inputs, dict):\n",
    "                for k, v in all_inputs.items():\n",
    "                    print(f\"  {k}: {type(v)}, shape={tuple(v.shape) if hasattr(v,'shape') else None}\")\n",
    "            elif isinstance(all_inputs, (list, tuple)):\n",
    "                for i, v in enumerate(all_inputs):\n",
    "                    print(f\"  idx {i}: {type(v)}, shape={tuple(v.shape) if hasattr(v,'shape') else None}\")\n",
    "            else:\n",
    "                print(\"  value:\", all_inputs)\n",
    "        return val_loss\n",
    "\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        all_inputs, y = self._prepare_tft_inputs(batch)\n",
    "        y_hat = self(all_inputs)\n",
    "        y_true = self._align_targets_to_decoder(y, y_hat)      # [B, T_dec, Q]，已自动扩到 Q 维\n",
    "\n",
    "        if hasattr(self, \"test_criterion\"):\n",
    "            loss = self.test_criterion.apply(y_true, y_hat, self.quantiles[1])\n",
    "        else:\n",
    "            loss = self.train_criterion.apply(y_hat, y_true)\n",
    "\n",
    "        self.log(\"test_loss\", loss, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        return loss\n",
    " \n",
    "\n",
    "    def configure_optimizers(self):\n",
    "   \n",
    "        hp = getattr(self, \"hparams\", None)\n",
    "        lr = float(getattr(hp, \"learning_rate\", 1e-3))\n",
    "        wd = float(getattr(hp, \"weight_decay\", 0.0))\n",
    "\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=lr, weight_decay=wd)\n",
    "\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode=\"min\", factor=0.5, patience=3, verbose=True\n",
    "    )\n",
    "\n",
    "    # Return dict form so Lightning knows which metric to monitor\n",
    "        return {\n",
    "        \"optimizer\": optimizer,\n",
    "        \"lr_scheduler\": {\n",
    "            \"scheduler\": scheduler,\n",
    "            \"monitor\": \"val_loss\",  # MUST match the key logged in validation_step\n",
    "            \"interval\": \"epoch\",    # Not used by Plateau but harmless\n",
    "            \"frequency\": 1,\n",
    "            \"strict\": True,         # Raise error if 'val_loss' is missing\n",
    "        },\n",
    "    }\n",
    "    def _accumulate_grad_flow(self):\n",
    "        \"\"\"Accumulate mean absolute gradient per layer (numbers only).\"\"\"\n",
    "        any_grad = False\n",
    "        for name, p in self.named_parameters():\n",
    "            if (p.grad is None) or (not p.requires_grad) or (\"bias\" in name):\n",
    "                continue\n",
    "            any_grad = True\n",
    "            i = self._gf_index.get(name, None)\n",
    "            if i is None:\n",
    "                continue\n",
    "            # detach to CPU scalar; keep it tiny\n",
    "            g = p.grad.detach().abs().mean().item()\n",
    "            self._gf_sum[i]   += g\n",
    "            self._gf_count[i] += 1\n",
    "        if any_grad:\n",
    "            self._gf_steps += 1\n",
    "\n",
    "    # ---- draw once at the end; save a single PNG; close figure immediately ----\n",
    "    def _plot_grad_flow_final(self, save_path=\"grad_flow_final.png\"):\n",
    "        \"\"\"Plot aggregated mean|grad| per layer collected during training.\"\"\"\n",
    "        # safe average per layer (ignore layers that never received grad)\n",
    "        denom = np.clip(self._gf_count, 1, None)\n",
    "        vals  = (self._gf_sum / denom).astype(np.float64)\n",
    "\n",
    "        # shorten very long layer names to fit x-axis\n",
    "        def _short(n):\n",
    "            n = n.replace(\".weight\", \"\")\n",
    "            parts = n.split(\".\")\n",
    "            return \".\".join(parts[-2:]) if len(parts) >= 2 else n\n",
    "\n",
    "        labels = [_short(n) for n in self._gf_layers]\n",
    "\n",
    "        # dynamic width to make x-axis fit\n",
    "        W = max(12.0, 0.18 * len(labels))  # 0.18 inch per label approximately\n",
    "        fig, ax = plt.subplots(figsize=(W, 5.5), constrained_layout=True)\n",
    "\n",
    "        ax.plot(vals, marker=\"o\", linewidth=1.0, alpha=0.9)\n",
    "        ax.hlines(0, 0, len(vals) - 1, linewidth=1)\n",
    "\n",
    "        # sparse ticks if too many layers\n",
    "        step = max(1, len(labels) // 60)  # at most ~60 tick labels\n",
    "        tick_pos = np.arange(0, len(labels), step)\n",
    "        ax.set_xticks(tick_pos)\n",
    "        ax.set_xticklabels([labels[i] for i in tick_pos], rotation=90, fontsize=7)\n",
    "\n",
    "        ax.set_xlim(-0.5, len(vals) - 0.5)\n",
    "        ax.set_xlabel(\"Layers\", fontsize=10)\n",
    "        ax.set_ylabel(\"Mean |gradient| (aggregated over training)\", fontsize=10)\n",
    "        ax.set_title(f\"Gradient flow (aggregated over {int(self._gf_steps)} steps)\", fontsize=11)\n",
    "        out_dir = Path(\"/Image\")            # absolute path you asked for\n",
    "        save_path = out_dir / \"grad_flow_final.png\"\n",
    "\n",
    "        fig.savefig(save_path, dpi=180)  # one image on disk\n",
    "        plt.close(fig)                   # no figure kept in memory\n",
    "        return save_path\n",
    "\n",
    "    # ---- hook into Lightning; accumulate numbers only during training ----\n",
    "    def on_after_backward(self):\n",
    "        # accumulate every N global steps; no plotting\n",
    "        if (self.trainer.global_step % self._gf_every) == 0:\n",
    "            self._accumulate_grad_flow()\n",
    "    def on_train_end(self):\n",
    "        path = self._plot_grad_flow_final(save_path=\"grad_flow_final.png\")\n",
    "        print(f\"[grad-flow] saved: {path}\")\n",
    "\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        # REQUIRED\n",
    "        return DataLoader(train_dataset, batch_size = self.minibatch_size, shuffle=True, drop_last=True, num_workers=4,persistent_workers=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        # OPTIONAL\n",
    "        return DataLoader(valid_dataset, batch_size = self.minibatch_size, shuffle=False, drop_last=False, num_workers=4,persistent_workers=True )\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        # OPTIONAL\n",
    "        return DataLoader(test_dataset, batch_size = self.minibatch_size, shuffle=False, drop_last=False, num_workers=4,persistent_workers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T03:09:35.443503Z",
     "start_time": "2020-04-22T03:09:35.417309Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda: 0\" if torch.cuda.is_available() else \"cpu\")\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Instance and fined parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T03:09:35.947089Z",
     "start_time": "2020-04-22T03:09:35.903770Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** TemporalFusionTransformer params ***\n",
      "# total_time_steps = 192\n",
      "# num_encoder_steps = 168\n",
      "# num_epochs = 100\n",
      "# early_stopping_patience = 5\n",
      "# multiprocessing_workers = 5\n",
      "# column_definition = [('identifier', <DataTypes.CATEGORICAL: 1>, <InputTypes.ID: 4>), ('days_from_start', <DataTypes.REAL_VALUED: 0>, <InputTypes.TIME: 5>), ('err_target', <DataTypes.REAL_VALUED: 0>, <InputTypes.TARGET: 0>), ('hour', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('day_of_week', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('forecast solar day ahead', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('forecast wind onshore day ahead', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('price day ahead', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('temp_weighted', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('temp_min_weighted', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('temp_max_weighted', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('pressure_weighted', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('humidity_weighted', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('wind_speed_weighted', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('wind_deg_weighted', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('rain_1h_weighted', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('rain_3h_weighted', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('snow_3h_weighted', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('clouds_all_weighted', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('total load forecast', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('price actual', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation biomass', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation fossil brown coal/lignite', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation fossil coal-derived gas', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation fossil gas', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation fossil hard coal', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation fossil oil', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation fossil oil shale', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation fossil peat', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation geothermal', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation hydro pumped storage consumption', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation hydro run-of-river and poundage', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation hydro water reservoir', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation marine', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation nuclear', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation other', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation other renewable', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation solar', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation waste', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation wind offshore', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation wind onshore', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('weather_main', <DataTypes.CATEGORICAL: 1>, <InputTypes.OBSERVED_INPUT: 1>), ('weather_description_simplified', <DataTypes.CATEGORICAL: 1>, <InputTypes.OBSERVED_INPUT: 1>)]\n",
      "# input_size = 41\n",
      "# output_size = 1\n",
      "# category_counts = [8, 21]\n",
      "# input_obs_loc = [0]\n",
      "# static_input_loc = []\n",
      "# known_regular_inputs = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
      "# known_categorical_inputs = []\n",
      "# dropout_rate = 0.1\n",
      "# hidden_layer_size = 64\n",
      "# learning_rate = 0.0005\n",
      "# minibatch_size = 64\n",
      "# max_gradient_norm = 1.0\n",
      "# num_heads = 2\n",
      "# stack_size = 1\n",
      "# weight_decay = 0.001\n",
      "# use_tlf = True\n",
      "# tlf_replace_with_seasonal = False\n",
      "# err_target = True\n",
      "training_step exists: True\n",
      "[CHK] final input_obs_loc = [19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]\n",
      "[MODEL] KNOWN = ['hour', 'day_of_week', 'forecast solar day ahead', 'forecast wind onshore day ahead', 'price day ahead', 'temp_weighted', 'temp_min_weighted', 'temp_max_weighted', 'pressure_weighted', 'humidity_weighted', 'wind_speed_weighted', 'wind_deg_weighted', 'rain_1h_weighted', 'rain_3h_weighted', 'snow_3h_weighted', 'clouds_all_weighted', 'total load forecast']\n",
      "[FMT]   KNOWN = ['hour', 'day_of_week', 'forecast solar day ahead', 'forecast wind onshore day ahead', 'price day ahead', 'temp_weighted', 'temp_min_weighted', 'temp_max_weighted', 'pressure_weighted', 'humidity_weighted', 'wind_speed_weighted', 'wind_deg_weighted', 'rain_1h_weighted', 'rain_3h_weighted', 'snow_3h_weighted', 'clouds_all_weighted', 'total load forecast']\n",
      "[DS]    KNOWN = ['hour', 'day_of_week', 'forecast solar day ahead', 'forecast wind onshore day ahead', 'price day ahead', 'temp_weighted', 'temp_min_weighted', 'temp_max_weighted', 'pressure_weighted', 'humidity_weighted', 'wind_speed_weighted', 'wind_deg_weighted', 'rain_1h_weighted', 'rain_3h_weighted', 'snow_3h_weighted', 'clouds_all_weighted', 'total load forecast']\n"
     ]
    }
   ],
   "source": [
    "# ==== Window ====\n",
    "hparams.num_encoder_steps = 168           # enc\n",
    "PRED = 24\n",
    "hparams.total_time_steps  = hparams.num_encoder_steps + PRED   # 192\n",
    "\n",
    "# ==== Model ====\n",
    "hparams.hidden_layer_size = 64\n",
    "hparams.num_heads         = 2\n",
    "hparams.dropout_rate      = 0.1\n",
    "hparams.weight_decay      = 1e-3\n",
    "\n",
    "# ==== Optimization ====\n",
    "hparams.minibatch_size    = 64\n",
    "hparams.learning_rate     = 5e-4\n",
    "hparams.max_gradient_norm = 1.0\n",
    "hparams.early_stopping_patience = 5\n",
    "hparams.use_tlf = use_tlf\n",
    "hparams.tlf_replace_with_seasonal = tlf_replace_with_seasonal\n",
    "hparams.err_target = err_target\n",
    "\n",
    "tft = TemporalFusionTransformer(hparams)  \n",
    "tft\n",
    "\n",
    "known_model = [n for (n, dt, role) in tft.column_definition\n",
    "               if role == InputTypes.KNOWN_INPUT and dt == DataTypes.REAL_VALUED]\n",
    "print(\"[MODEL] KNOWN =\", known_model)\n",
    "coldef_fmt = (data_formatter.get_column_definition()\n",
    "              if hasattr(data_formatter, \"get_column_definition\")\n",
    "              else data_formatter._column_definition)\n",
    "known_fmt = [n for (n, dt, role) in coldef_fmt\n",
    "             if role == InputTypes.KNOWN_INPUT and dt == DataTypes.REAL_VALUED]\n",
    "print(\"[FMT]   KNOWN =\", known_fmt)\n",
    "coldef_ds = (train_dataset.get_column_definition()\n",
    "             if hasattr(train_dataset, \"get_column_definition\")\n",
    "             else getattr(train_dataset, \"_column_definition\", None))\n",
    "known_ds = [n for (n, dt, role) in (coldef_ds or [])\n",
    "            if role == InputTypes.KNOWN_INPUT and dt == DataTypes.REAL_VALUED]\n",
    "print(\"[DS]    KNOWN =\", known_ds)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T03:09:37.696931Z",
     "start_time": "2020-04-22T03:09:37.694439Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "early_stop_callback = EarlyStopping(monitor = 'val_loss',\n",
    "                                    min_delta = 1e-4,\n",
    "                                    patience=hparams.early_stopping_patience,\n",
    "                                    verbose=False,\n",
    "                                    mode='min')\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_loss',\n",
    "    save_top_k=1,\n",
    "    mode='min',\n",
    "    filename='best-checkpoint',  \n",
    "    verbose=True\n",
    ")\n",
    "from pytorch_lightning.callbacks import TQDMProgressBar\n",
    "\n",
    "class CustomProgressBar(TQDMProgressBar):\n",
    "    def get_metrics(self, *args, **kwargs):\n",
    "        metrics = super().get_metrics(*args, **kwargs)\n",
    "        metrics.pop(\"v_num\", None) \n",
    "        return metrics\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-04-22T03:09:48.709Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..\n",
      "`Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..\n"
     ]
    }
   ],
   "source": [
    "# tb_logger = TensorBoardLogger(save_dir=\"lightning_logs\", name=\"tft\")\n",
    "lr_monitor = LearningRateMonitor(logging_interval=\"epoch\")\n",
    "tb_logger = TensorBoardLogger(save_dir=\"lightning_logs\", name=\"tft\")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=100,\n",
    "    accelerator=\"cpu\", devices=1,                    \n",
    "    logger=tb_logger,\n",
    "    log_every_n_steps=20,\n",
    "    gradient_clip_val=2.0,\n",
    "    gradient_clip_algorithm=\"norm\",\n",
    "    callbacks=[\n",
    "        early_stop_callback,\n",
    "        checkpoint_callback,\n",
    "        lr_monitor,\n",
    "        CustomProgressBar()\n",
    "    ],\n",
    "    limit_train_batches=1.0,               \n",
    "    limit_val_batches=1.0,\n",
    "    num_sanity_val_steps=2,\n",
    "    deterministic=True\n",
    ")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(tft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at lightning_logs/tft/version_E1/checkpoints/best-checkpoint.ckpt\n",
      "/Users/guanyuxiaoxiong/opt/anaconda3/envs/tft-env/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:282: Be aware that when using `ckpt_path`, callbacks used to create the checkpoint need to be provided during `Trainer` instantiation. Please add the following callbacks: [\"EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}\", \"ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}\"].\n",
      "Loaded model weights from the checkpoint at lightning_logs/tft/version_E1/checkpoints/best-checkpoint.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|█████████████████████| 46/46 [00:39<00:00,  1.15it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5090025067329407\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "[{'test_loss': 0.5090025067329407}]\n",
      "0.5090025067329407\n"
     ]
    }
   ],
   "source": [
    "version_dir = \"lightning_logs/tft/version_E1\"\n",
    "\n",
    "def latest_ckpt(d):\n",
    "    cands = glob.glob(os.path.join(d, \"checkpoints\", \"*.ckpt\"))\n",
    "    if not cands:\n",
    "        raise FileNotFoundError(f\"No ckpt under {d}/checkpoints\")\n",
    "    best = [p for p in cands if \"best\" in os.path.basename(p).lower()]\n",
    "    if best: return max(best, key=os.path.getmtime)\n",
    "    last = [p for p in cands if \"last\" in os.path.basename(p).lower()]\n",
    "    if last: return max(last, key=os.path.getmtime)\n",
    "    return max(cands, key=os.path.getmtime)\n",
    "\n",
    "ckpt_path = latest_ckpt(version_dir)\n",
    "\n",
    "\n",
    "results = trainer.test(model=tft, ckpt_path=ckpt_path)  \n",
    "print(results)                      # [{'test_loss': ... , ...}]\n",
    "print(results[0].get(\"test_loss\"))  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-29T23:02:02.935152Z",
     "start_time": "2020-03-29T23:02:02.932563Z"
    }
   },
   "source": [
    "## Top-K Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** TemporalFusionTransformer params ***\n",
      "# total_time_steps = 192\n",
      "# num_encoder_steps = 168\n",
      "# num_epochs = 100\n",
      "# early_stopping_patience = 10\n",
      "# multiprocessing_workers = 5\n",
      "# column_definition = [('identifier', <DataTypes.CATEGORICAL: 1>, <InputTypes.ID: 4>), ('days_from_start', <DataTypes.REAL_VALUED: 0>, <InputTypes.TIME: 5>), ('err_target', <DataTypes.REAL_VALUED: 0>, <InputTypes.TARGET: 0>), ('hour', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('day_of_week', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('forecast solar day ahead', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('forecast wind onshore day ahead', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('price day ahead', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('temp_weighted', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('temp_min_weighted', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('temp_max_weighted', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('pressure_weighted', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('humidity_weighted', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('wind_speed_weighted', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('wind_deg_weighted', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('rain_1h_weighted', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('rain_3h_weighted', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('snow_3h_weighted', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('clouds_all_weighted', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('total load forecast', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('price actual', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation biomass', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation fossil brown coal/lignite', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation fossil coal-derived gas', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation fossil gas', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation fossil hard coal', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation fossil oil', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation fossil oil shale', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation fossil peat', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation geothermal', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation hydro pumped storage consumption', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation hydro run-of-river and poundage', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation hydro water reservoir', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation marine', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation nuclear', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation other', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation other renewable', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation solar', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation waste', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation wind offshore', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation wind onshore', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('weather_main', <DataTypes.CATEGORICAL: 1>, <InputTypes.OBSERVED_INPUT: 1>), ('weather_description_simplified', <DataTypes.CATEGORICAL: 1>, <InputTypes.OBSERVED_INPUT: 1>)]\n",
      "# input_size = 41\n",
      "# output_size = 1\n",
      "# category_counts = [8, 21]\n",
      "# input_obs_loc = [19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]\n",
      "# static_input_loc = []\n",
      "# known_regular_inputs = [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]\n",
      "# known_categorical_inputs = []\n",
      "# dropout_rate = 0.1\n",
      "# hidden_layer_size = 64\n",
      "# learning_rate = 0.0005\n",
      "# minibatch_size = 64\n",
      "# max_gradient_norm = 1.0\n",
      "# num_heads = 2\n",
      "# stack_size = 1\n",
      "# weight_decay = 0.001\n",
      "# use_tlf = True\n",
      "# tlf_replace_with_seasonal = False\n",
      "# err_target = True\n",
      "# num_non_static_historical_inputs = 38\n",
      "# num_non_static_future_inputs = 17\n",
      "training_step exists: True\n",
      "[CHK] final input_obs_loc = [19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]\n",
      "[TopK preflight] inferred from loader -> hist=38, fut=17 ; model expects -> hist=38, fut=17\n",
      "\n",
      "[Info] static_vsn not captured or not present.\n",
      "\n",
      "=== Historical VSN (encoder)  (version=E3) — Top-20 ===\n",
      "  0.097381  generation wind onshore\n",
      "  0.095575  wind_speed_weighted\n",
      "  0.087825  snow_3h_weighted\n",
      "  0.051054  price actual\n",
      "  0.049125  generation hydro pumped storage consumption\n",
      "  0.042456  generation fossil hard coal\n",
      "  0.039043  temp_weighted\n",
      "  0.030609  humidity_weighted\n",
      "  0.028780  generation hydro water reservoir\n",
      "  0.028023  pressure_weighted\n",
      "  0.026013  generation fossil gas\n",
      "  0.024601  generation wind offshore\n",
      "  0.023830  generation fossil brown coal/lignite\n",
      "  0.023228  generation biomass\n",
      "  0.022911  price day ahead\n",
      "  0.021133  day_of_week\n",
      "  0.020978  generation solar\n",
      "  0.020449  generation nuclear\n",
      "  0.019813  weather_main\n",
      "  0.019402  generation geothermal\n",
      "\n",
      "=== Future VSN (decoder)  (version=E3) — Top-17 ===\n",
      "  0.142853  total load forecast\n",
      "  0.082699  pressure_weighted\n",
      "  0.080505  forecast wind onshore day ahead\n",
      "  0.073329  rain_1h_weighted\n",
      "  0.066866  price day ahead\n",
      "  0.065625  temp_min_weighted\n",
      "  0.063105  clouds_all_weighted\n",
      "  0.057170  day_of_week\n",
      "  0.054519  temp_weighted\n",
      "  0.054343  wind_deg_weighted\n",
      "  0.050673  hour\n",
      "  0.048449  temp_max_weighted\n",
      "  0.039025  wind_speed_weighted\n",
      "  0.035429  humidity_weighted\n",
      "  0.032186  rain_3h_weighted\n",
      "  0.028897  snow_3h_weighted\n",
      "  0.024327  forecast solar day ahead\n",
      "Saved figures to: Image/TopK\n"
     ]
    }
   ],
   "source": [
    "# run_tft_topk.py\n",
    "# Main entry to compute and visualize Top-K VSN variable importances.\n",
    "\n",
    "from types import SimpleNamespace\n",
    "\n",
    "from Evaluation.tft_topk import (\n",
    "    latest_ckpt,\n",
    "    move_to,\n",
    "    unpack_batch_for_io,\n",
    "    extract_version_suffix,\n",
    "    assert_loader_matches_model,\n",
    "    collect_vsn_means,\n",
    "    names_from_column_definition,\n",
    "    topk_print,\n",
    "    _to_np,\n",
    "    plot_var_bars,\n",
    ")\n",
    "\n",
    "# -------- Config --------\n",
    "VERSION_DIR = \"lightning_logs/tft/version_E3\"\n",
    "DEVICE      = \"cpu\"          # or \"cuda\"\n",
    "MAX_BATCHES = 0              # 0 = full val set\n",
    "TOPK_PRINT  = 20             # Top-K to print in console; set as you like\n",
    "TOPK_BARS   = None           # If int, only plot top-K bars; None = plot all\n",
    "OUT_DIR     = \"Image/TopK\"   # where to save plots\n",
    "\n",
    "def main():\n",
    "    # --- Restore model with EXACT hparams from checkpoint ---\n",
    "    ckpt_path = latest_ckpt(VERSION_DIR)\n",
    "    device = torch.device(DEVICE)\n",
    "\n",
    "    ckpt = torch.load(ckpt_path, map_location=device)\n",
    "    raw_hp = ckpt.get(\"hyper_parameters\", {})\n",
    "    raw_hp = raw_hp.get(\"hparams\", raw_hp) if isinstance(raw_hp, dict) else raw_hp\n",
    "    hparams = SimpleNamespace(**raw_hp) if isinstance(raw_hp, dict) else raw_hp\n",
    "\n",
    "    model = TemporalFusionTransformer(hparams).to(device)\n",
    "    _ = model.load_state_dict(ckpt[\"state_dict\"], strict=False)\n",
    "    model.eval()\n",
    "    try:\n",
    "        model.log = lambda *a, **k: None\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # --- Dataloader from the SAME experiment config (val -> fallback train) ---\n",
    "    try:\n",
    "        loader = model.val_dataloader()\n",
    "    except Exception:\n",
    "        loader = None\n",
    "    if loader is None:\n",
    "        try:\n",
    "            loader = model.train_dataloader()\n",
    "        except Exception:\n",
    "            raise RuntimeError(\"Neither val_dataloader nor train_dataloader is available.\")\n",
    "\n",
    "    # --- Preflight: confirm loader feature counts match checkpoint ---\n",
    "    assert_loader_matches_model(model, loader)\n",
    "\n",
    "    # --- Collect global mean VSN weights ---\n",
    "    w_static_mean, w_hist_mean, w_future_mean = collect_vsn_means(model, loader, max_batches=MAX_BATCHES)\n",
    "\n",
    "    # --- Names for pretty printing/plots ---\n",
    "    n_s = int(w_static_mean.shape[0]) if w_static_mean is not None else 0\n",
    "    n_h = int(w_hist_mean.shape[0])   if w_hist_mean   is not None else 0\n",
    "    n_f = int(w_future_mean.shape[0]) if w_future_mean is not None else 0\n",
    "    s_names, h_names, f_names = names_from_column_definition(model, n_s, n_h, n_f)\n",
    "\n",
    "    # --- Print Top-K to console ---\n",
    "    ver = extract_version_suffix(VERSION_DIR)\n",
    "    if w_static_mean is not None:\n",
    "        topk_print(w_static_mean, s_names, f\"Static VSN  (version={ver})\", TOPK_PRINT)\n",
    "    else:\n",
    "        print(\"\\n[Info] static_vsn not captured or not present.\")\n",
    "    if w_hist_mean is not None:\n",
    "        topk_print(w_hist_mean,   h_names, f\"Historical VSN (encoder)  (version={ver})\", TOPK_PRINT)\n",
    "    else:\n",
    "        print(\"\\n[Info] temporal_historical_vsn not captured or not present.\")\n",
    "    if w_future_mean is not None:\n",
    "        topk_print(w_future_mean, f_names, f\"Future VSN (decoder)  (version={ver})\", TOPK_PRINT,  )\n",
    "    else:\n",
    "        print(\"\\n[Info] temporal_future_vsn not captured or not present.\")\n",
    "\n",
    "    # --- Plots ---\n",
    "    arr_static = _to_np(w_static_mean)\n",
    "    arr_hist   = _to_np(w_hist_mean)\n",
    "    arr_future = _to_np(w_future_mean)\n",
    "\n",
    "    if arr_static is not None:\n",
    "        plot_var_bars(s_names, arr_static, f\"Static VSN — mean weight (version={ver})\",\n",
    "                      filename=f\"vsn_bars_static_v{ver}\", out_dir=OUT_DIR, topk=TOPK_BARS)\n",
    "    if arr_hist is not None:\n",
    "        plot_var_bars(h_names, arr_hist,   f\"Historical VSN — mean weight (version={ver})\",\n",
    "                      filename=f\"vsn_bars_hist_v{ver}\", out_dir=OUT_DIR, topk=TOPK_BARS)\n",
    "    if arr_future is not None:\n",
    "        plot_var_bars(f_names, arr_future, f\"Future VSN — mean weight (version={ver})\",\n",
    "                      filename=f\"vsn_bars_future_v{ver}\", out_dir=OUT_DIR, topk=TOPK_BARS,)\n",
    "\n",
    "    print(\"Saved figures to:\", OUT_DIR)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ablation analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** TemporalFusionTransformer params ***\n",
      "# total_time_steps = 192\n",
      "# num_encoder_steps = 168\n",
      "# num_epochs = 100\n",
      "# early_stopping_patience = 10\n",
      "# multiprocessing_workers = 5\n",
      "# column_definition = [('identifier', <DataTypes.CATEGORICAL: 1>, <InputTypes.ID: 4>), ('days_from_start', <DataTypes.REAL_VALUED: 0>, <InputTypes.TIME: 5>), ('err_target', <DataTypes.REAL_VALUED: 0>, <InputTypes.TARGET: 0>), ('hour', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('day_of_week', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('forecast solar day ahead', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('forecast wind onshore day ahead', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('price day ahead', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('temp_weighted', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('temp_min_weighted', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('temp_max_weighted', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('pressure_weighted', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('humidity_weighted', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('wind_speed_weighted', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('wind_deg_weighted', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('rain_1h_weighted', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('rain_3h_weighted', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('snow_3h_weighted', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('clouds_all_weighted', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('total load forecast', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('price actual', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation biomass', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation fossil brown coal/lignite', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation fossil coal-derived gas', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation fossil gas', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation fossil hard coal', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation fossil oil', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation fossil oil shale', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation fossil peat', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation geothermal', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation hydro pumped storage consumption', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation hydro run-of-river and poundage', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation hydro water reservoir', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation marine', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation nuclear', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation other', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation other renewable', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation solar', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation waste', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation wind offshore', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation wind onshore', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('weather_main', <DataTypes.CATEGORICAL: 1>, <InputTypes.OBSERVED_INPUT: 1>), ('weather_description_simplified', <DataTypes.CATEGORICAL: 1>, <InputTypes.OBSERVED_INPUT: 1>)]\n",
      "# input_size = 41\n",
      "# output_size = 1\n",
      "# category_counts = [8, 21]\n",
      "# input_obs_loc = [19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]\n",
      "# static_input_loc = []\n",
      "# known_regular_inputs = [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]\n",
      "# known_categorical_inputs = []\n",
      "# dropout_rate = 0.1\n",
      "# hidden_layer_size = 64\n",
      "# learning_rate = 0.0005\n",
      "# minibatch_size = 64\n",
      "# max_gradient_norm = 1.0\n",
      "# num_heads = 2\n",
      "# stack_size = 1\n",
      "# weight_decay = 0.001\n",
      "# use_tlf = True\n",
      "# tlf_replace_with_seasonal = False\n",
      "# err_target = True\n",
      "# num_non_static_historical_inputs = 38\n",
      "# num_non_static_future_inputs = 17\n",
      "training_step exists: True\n",
      "[CHK] final input_obs_loc = [19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]\n",
      "[Ablation preflight] inferred from loader -> hist=38, fut=17 ; model expects -> hist=38, fut=17\n",
      "\n",
      "Saved ablation table: Image/DMAC/ablation_permute.csv\n",
      "[Baseline] mean loss over 9 batch(es): 0.923102\n",
      "\n",
      "Top 20 variables by impact (%): (mode=permute, batches=9)\n",
      "  40.502%  Δ=  0.373875  loss'=  1.296977  hour\n",
      "  33.049%  Δ=  0.305073  loss'=  1.228175  total load forecast\n",
      "   6.990%  Δ=  0.064529  loss'=  0.987631  forecast solar day ahead\n",
      "   6.004%  Δ=  0.055427  loss'=  0.978529  temp_max_weighted\n",
      "   5.557%  Δ=  0.051299  loss'=  0.974402  temp_weighted\n",
      "   5.061%  Δ=  0.046722  loss'=  0.969824  temp_min_weighted\n",
      "   4.767%  Δ=  0.044004  loss'=  0.967106  generation fossil hard coal\n",
      "   3.114%  Δ=  0.028743  loss'=  0.951846  price day ahead\n",
      "   3.114%  Δ=  0.028741  loss'=  0.951843  day_of_week\n",
      "   2.475%  Δ=  0.022850  loss'=  0.945953  forecast wind onshore day ahead\n",
      "   1.807%  Δ=  0.016684  loss'=  0.939787  generation fossil oil\n",
      "   1.740%  Δ=  0.016061  loss'=  0.939163  generation hydro run-of-river and poundage\n",
      "   1.703%  Δ=  0.015721  loss'=  0.938824  generation waste\n",
      "   1.435%  Δ=  0.013249  loss'=  0.936352  wind_deg_weighted\n",
      "   1.230%  Δ=  0.011351  loss'=  0.934454  price actual\n",
      "   0.793%  Δ=  0.007317  loss'=  0.930419  rain_1h_weighted\n",
      "   0.761%  Δ=  0.007027  loss'=  0.930129  generation other\n",
      "   0.466%  Δ=  0.004305  loss'=  0.927408  generation fossil brown coal/lignite\n",
      "   0.370%  Δ=  0.003418  loss'=  0.926520  humidity_weighted\n",
      "   0.022%  Δ=  0.000199  loss'=  0.923302  generation hydro water reservoir\n",
      "Saved figures to: Image/DMAC\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from types import SimpleNamespace\n",
    "\n",
    "from Evaluation.tft_ablation import (\n",
    "    latest_ckpt,\n",
    "    names_from_column_definition,\n",
    "    run_ablation,\n",
    "    save_ablation_csv,\n",
    "    plot_ablation,\n",
    "    assert_loader_matches_model,\n",
    "       # <-- requires the preflight helper added in tft_ablation.py\n",
    ")\n",
    "\n",
    "# -------- Config --------\n",
    "VERSION_DIR = \"lightning_logs/tft/version_E3\"\n",
    "DEVICE      = \"cpu\"            # or \"cuda\"\n",
    "MODE        = \"permute\"        # \"permute\" or \"zero\"\n",
    "SEED        = 42\n",
    "MAX_BATCHES = 0                # 0 = full val set\n",
    "VAR_LIST    = None             # e.g. [\"rain_3h_weighted\", \"temp_weighted\"]; None = all KNOWN+OBSERVED\n",
    "OUT_DIR     = \"Image/DMAC\"\n",
    "CSV_NAME    = f\"ablation_{MODE}.csv\"\n",
    "\n",
    "\n",
    "def main():\n",
    "    # --- Load model from checkpoint hparams (shape-safe) ---\n",
    "    ckpt_path = latest_ckpt(VERSION_DIR)\n",
    "    device = torch.device(DEVICE)\n",
    "\n",
    "    ckpt = torch.load(ckpt_path, map_location=device)\n",
    "    raw_hp = ckpt.get(\"hyper_parameters\", {})\n",
    "    raw_hp = raw_hp.get(\"hparams\", raw_hp) if isinstance(raw_hp, dict) else raw_hp\n",
    "    hparams = SimpleNamespace(**raw_hp) if isinstance(raw_hp, dict) else raw_hp\n",
    "\n",
    "    # Adjust this import to your project if needed\n",
    "    model = TemporalFusionTransformer(hparams).to(device)\n",
    "    _ = model.load_state_dict(ckpt[\"state_dict\"], strict=False)\n",
    "    model.eval()\n",
    "    try:\n",
    "        model.log = lambda *a, **k: None  # silence self.log during manual evaluation\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # --- Get DataLoader (val -> fallback train); both should be built using hparams above ---\n",
    "    try:\n",
    "        loader = model.val_dataloader()\n",
    "    except Exception:\n",
    "        loader = None\n",
    "    if loader is None:\n",
    "        try:\n",
    "            loader = model.train_dataloader()\n",
    "        except Exception:\n",
    "            raise RuntimeError(\"No val/train dataloader available.\")\n",
    "\n",
    "    # --- Preflight: ensure loader feature counts match checkpoint expectations ---\n",
    "    assert_loader_matches_model(model, loader)\n",
    "\n",
    "    # --- Discover variable names for ablation list ---\n",
    "    obs_names, knw_names = names_from_column_definition(model)\n",
    "\n",
    "    # --- Run ablation ---\n",
    "    rows, baseline, n_batches = run_ablation(\n",
    "        model=model,\n",
    "        loader=loader,\n",
    "        observed_names=obs_names,\n",
    "        known_names=knw_names,\n",
    "        mode=MODE,\n",
    "        max_batches=MAX_BATCHES,\n",
    "        var_list=VAR_LIST,\n",
    "        device=device,\n",
    "        seed=SEED,\n",
    "    )\n",
    "\n",
    "    # --- Save CSV ---\n",
    "    csv_path = save_ablation_csv(rows, OUT_DIR, CSV_NAME)\n",
    "    print(f\"\\nSaved ablation table: {csv_path}\")\n",
    "    print(f\"[Baseline] mean loss over {n_batches} batch(es): {baseline:.6f}\")\n",
    "\n",
    "    # --- Print top-k summary ---\n",
    "    top_k = min(20, len(rows))\n",
    "    print(f\"\\nTop {top_k} variables by impact (%): (mode={MODE}, batches={n_batches if MAX_BATCHES==0 else MAX_BATCHES})\")\n",
    "    for var, pert_mean, delta, pct in rows[:top_k]:\n",
    "        print(f\"{pct:8.3f}%  Δ={delta:10.6f}  loss'={pert_mean:10.6f}  {var}\")\n",
    "\n",
    "    # --- Figures (titles include version suffix parsed from VERSION_DIR) ---\n",
    "    plot_ablation(rows, baseline, OUT_DIR, VERSION_DIR, n_batches, MODE)\n",
    "    print(\"Saved figures to:\", OUT_DIR)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrated Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** TemporalFusionTransformer params ***\n",
      "# total_time_steps = 192\n",
      "# num_encoder_steps = 168\n",
      "# num_epochs = 100\n",
      "# early_stopping_patience = 10\n",
      "# multiprocessing_workers = 5\n",
      "# column_definition = [('identifier', <DataTypes.CATEGORICAL: 1>, <InputTypes.ID: 4>), ('days_from_start', <DataTypes.REAL_VALUED: 0>, <InputTypes.TIME: 5>), ('err_target', <DataTypes.REAL_VALUED: 0>, <InputTypes.TARGET: 0>), ('hour', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('day_of_week', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('forecast solar day ahead', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('forecast wind onshore day ahead', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('price day ahead', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('temp_weighted', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('temp_min_weighted', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('temp_max_weighted', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('pressure_weighted', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('humidity_weighted', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('wind_speed_weighted', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('wind_deg_weighted', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('rain_1h_weighted', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('rain_3h_weighted', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('snow_3h_weighted', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('clouds_all_weighted', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('total load forecast', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('price actual', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation biomass', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation fossil brown coal/lignite', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation fossil coal-derived gas', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation fossil gas', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation fossil hard coal', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation fossil oil', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation fossil oil shale', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation fossil peat', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation geothermal', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation hydro pumped storage consumption', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation hydro run-of-river and poundage', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation hydro water reservoir', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation marine', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation nuclear', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation other', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation other renewable', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation solar', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation waste', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation wind offshore', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation wind onshore', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('weather_main', <DataTypes.CATEGORICAL: 1>, <InputTypes.OBSERVED_INPUT: 1>), ('weather_description_simplified', <DataTypes.CATEGORICAL: 1>, <InputTypes.OBSERVED_INPUT: 1>)]\n",
      "# input_size = 41\n",
      "# output_size = 1\n",
      "# category_counts = [8, 21]\n",
      "# input_obs_loc = [19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]\n",
      "# static_input_loc = []\n",
      "# known_regular_inputs = [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]\n",
      "# known_categorical_inputs = []\n",
      "# dropout_rate = 0.1\n",
      "# hidden_layer_size = 64\n",
      "# learning_rate = 0.0005\n",
      "# minibatch_size = 64\n",
      "# max_gradient_norm = 1.0\n",
      "# num_heads = 2\n",
      "# stack_size = 1\n",
      "# weight_decay = 0.001\n",
      "# use_tlf = True\n",
      "# tlf_replace_with_seasonal = False\n",
      "# err_target = True\n",
      "# num_non_static_historical_inputs = 38\n",
      "# num_non_static_future_inputs = 17\n",
      "training_step exists: True\n",
      "[CHK] final input_obs_loc = [19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]\n",
      "Saved: Image/IG/ig_known_sample0_faceted.png  |  Image/IG/ig_known_sample0_faceted.svg\n",
      "Saved: Image/IG/ig_observed_sample0_faceted.png  |  Image/IG/ig_observed_sample0_faceted.svg\n"
     ]
    }
   ],
   "source": [
    "# run_tft_ig.py  — adapted main program for your current setup\n",
    "\n",
    "import torch\n",
    "import os, re \n",
    "from types import SimpleNamespace\n",
    "from Evaluation.tft_ig_lib import (\n",
    "    latest_ckpt, move_to, ensure_dir,\n",
    "    names_from_column_definition, unpack_batch_for_io, select_single_sample,\n",
    "    integrated_gradients_single_input, topk_indices_by_total_abs, plot_time_curves,\n",
    ")\n",
    "\n",
    "# ---- Config ----\n",
    "VERSION_DIR, DEVICE = \"lightning_logs/tft/version_E3\", \"cpu\"\n",
    "SAMPLE_IDX, IG_STEPS, TOPK = 0, 32, 8\n",
    "SAVE_DIR, ZERO_BASELINE = \"Image/IG\", True\n",
    "\n",
    "def extract_version_suffix(version_dir: str) -> str:\n",
    "    base = os.path.basename(version_dir.rstrip(\"/\"))\n",
    "    m = re.search(r\"version[_\\-]?(.+)$\", base)\n",
    "    return m.group(1) if m else base\n",
    "\n",
    "\n",
    "def main():\n",
    "    device = torch.device(DEVICE)\n",
    "\n",
    "    # --- Restore model with EXACT hparams from checkpoint (avoid shape mismatches) ---\n",
    "    ckpt_path = latest_ckpt(VERSION_DIR)\n",
    "    ckpt = torch.load(ckpt_path, map_location=device)\n",
    "    raw_hp = ckpt.get(\"hyper_parameters\", {})\n",
    "    raw_hp = raw_hp.get(\"hparams\", raw_hp) if isinstance(raw_hp, dict) else raw_hp\n",
    "    hparams = SimpleNamespace(**raw_hp) if isinstance(raw_hp, dict) else raw_hp\n",
    "\n",
    "    model = TemporalFusionTransformer(hparams).to(device)\n",
    "    _ = model.load_state_dict(ckpt[\"state_dict\"], strict=False)\n",
    "    model.eval()\n",
    "    try:\n",
    "        model.log = lambda *a, **k: None\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # --- Use the dataloader built from the SAME experiment config ---\n",
    "    try:\n",
    "        loader = model.val_dataloader()\n",
    "    except Exception:\n",
    "        loader = None\n",
    "    if loader is None:\n",
    "        try:\n",
    "            loader = model.train_dataloader()\n",
    "        except Exception:\n",
    "            raise RuntimeError(\"No val/train dataloader available.\")\n",
    "\n",
    "    # --- Preflight: run one forward via _prepare_tft_inputs to validate shapes ---\n",
    "    batch = move_to(next(iter(loader)), device)\n",
    "    packed = unpack_batch_for_io(batch)\n",
    "    try:\n",
    "        all_inputs, _ = model._prepare_tft_inputs(packed)\n",
    "        _ = model(all_inputs)  # single forward to ensure loader matches checkpoint\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(\n",
    "            \"DataLoader/ckpt feature configuration mismatch. \"\n",
    "            \"Please ensure this loader was built with the SAME column_definition/data_formatter as the checkpoint.\"\n",
    "        ) from e\n",
    "\n",
    "    # --- Pick one sample from the batch for IG ---\n",
    "    single = select_single_sample(packed, SAMPLE_IDX)\n",
    "\n",
    "    # --- Variable names (for plotting legends); will be padded below if needed ---\n",
    "    obs_names, knw_names = names_from_column_definition(model)\n",
    "\n",
    "    # --- Integrated Gradients for KNOWN/OBSERVED streams ---\n",
    "    attr_known = integrated_gradients_single_input(\n",
    "        model, single, which=\"known\", steps=IG_STEPS, zero_baseline=ZERO_BASELINE, device=device\n",
    "    )\n",
    "    attr_observed = integrated_gradients_single_input(\n",
    "        model, single, which=\"observed\", steps=IG_STEPS, zero_baseline=ZERO_BASELINE, device=device\n",
    "    )\n",
    "\n",
    "    # --- Ensure we have names for every channel that appears in attributions ---\n",
    "    if attr_known is not None:\n",
    "        V_k = attr_known.shape[-1]\n",
    "        if not knw_names or len(knw_names) < V_k:\n",
    "            base = len(knw_names or [])\n",
    "            knw_names = (knw_names or []) + [f\"known_{i}\" for i in range(base, V_k)]\n",
    "    if attr_observed is not None:\n",
    "        V_h = attr_observed.shape[-1]\n",
    "        if not obs_names or len(obs_names) < V_h:\n",
    "            base = len(obs_names or [])\n",
    "            obs_names = (obs_names or []) + [f\"observed_{i}\" for i in range(base, V_h)]\n",
    "\n",
    "    # --- Plot & save ---\n",
    "    ver = extract_version_suffix(VERSION_DIR)  # e.g., \"E1\"\n",
    "    ensure_dir(SAVE_DIR)\n",
    "\n",
    "    plot_time_curves(\n",
    "    attr_known,\n",
    "    knw_names,\n",
    "    topk_indices_by_total_abs(attr_known, TOPK),\n",
    "    f\"IG — KNOWN (version={ver}) · sample {SAMPLE_IDX}\",\n",
    "    f\"{SAVE_DIR}/ig_known_sample{SAMPLE_IDX}_faceted.png\",\n",
    "    # optional kwargs for faceting:\n",
    "    types_map=None,     # auto infer: Price / Fossil / Renewable / Weather / Other\n",
    "    col_wrap=2,         # 2 columns of subplots; change to 3 if you有很多类型\n",
    "    sharey=False        # each facet has its own y-scale (更易读)\n",
    ")\n",
    "\n",
    "    plot_time_curves(\n",
    "    attr_observed,\n",
    "    obs_names,\n",
    "    topk_indices_by_total_abs(attr_observed, TOPK),\n",
    "    f\"IG — OBSERVED (version={ver}) · sample {SAMPLE_IDX}\",\n",
    "    f\"{SAVE_DIR}/ig_observed_sample{SAMPLE_IDX}_faceted.png\",\n",
    "    types_map=None,\n",
    "    col_wrap=2,\n",
    "    sharey=False\n",
    "      )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Only For E3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total Load Forecast Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall test loss: 474.1687927246094\n",
      "Normalized Quantile Loss (tau=0.1): 0.011410183273255825\n",
      "Normalized Quantile Loss (tau=0.5): 0.01101555023342371\n",
      "Normalized Quantile Loss (tau=0.9): 0.01062091439962387\n"
     ]
    }
   ],
   "source": [
    "# 1. Load the dataset\n",
    "df = pd.read_csv(\"data/electricty.csv\")\n",
    "\n",
    "# ⚠️ Replace with your actual column names\n",
    "y_true = torch.tensor(df[\"target\"].values, dtype=torch.float32)\n",
    "y_pred = torch.tensor(df[\"total load forecast\"].values, dtype=torch.float32)\n",
    "\n",
    "\n",
    "# Assume you trained with three quantiles\n",
    "quantiles = [0.1, 0.5, 0.9]\n",
    "output_size = 1   # one prediction value per time step\n",
    "\n",
    "ql_calc = QuantileLossCalculator(quantiles, output_size)\n",
    "\n",
    "# To match the input format of QuantileLossCalculator,\n",
    "# we need to concatenate y_true / y_pred along quantile dimension: [N, output_size * num_quantiles]\n",
    "a_targets = torch.cat([y_true.unsqueeze(1) for _ in quantiles], dim=1)  # [N, len(quantiles)]\n",
    "b_preds   = torch.cat([y_pred.unsqueeze(1) for _ in quantiles], dim=1)  # [N, len(quantiles)]\n",
    "\n",
    "# 3. Compute the overall test loss (mean across all time steps and quantiles)\n",
    "test_loss = ql_calc.apply(b_preds, a_targets)\n",
    "print(\"Overall test loss:\", test_loss.item())\n",
    "\n",
    "# 4. Optionally, compute Normalized Quantile Loss (NQL) for each quantile\n",
    "nql_calc = NormalizedQuantileLossCalculator(quantiles, output_size)\n",
    "for tau in quantiles:\n",
    "    nql = nql_calc.apply(y_true, y_pred, tau)\n",
    "    print(f\"Normalized Quantile Loss (tau={tau}): {nql.item()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E3 Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** TemporalFusionTransformer params ***\n",
      "# total_time_steps = 192\n",
      "# num_encoder_steps = 168\n",
      "# num_epochs = 100\n",
      "# early_stopping_patience = 10\n",
      "# multiprocessing_workers = 5\n",
      "# column_definition = [('identifier', <DataTypes.CATEGORICAL: 1>, <InputTypes.ID: 4>), ('days_from_start', <DataTypes.REAL_VALUED: 0>, <InputTypes.TIME: 5>), ('err_target', <DataTypes.REAL_VALUED: 0>, <InputTypes.TARGET: 0>), ('hour', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('day_of_week', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('forecast solar day ahead', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('forecast wind onshore day ahead', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('price day ahead', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('temp_weighted', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('temp_min_weighted', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('temp_max_weighted', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('pressure_weighted', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('humidity_weighted', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('wind_speed_weighted', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('wind_deg_weighted', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('rain_1h_weighted', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('rain_3h_weighted', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('snow_3h_weighted', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('clouds_all_weighted', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('total load forecast', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('price actual', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation biomass', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation fossil brown coal/lignite', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation fossil coal-derived gas', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation fossil gas', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation fossil hard coal', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation fossil oil', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation fossil oil shale', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation fossil peat', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation geothermal', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation hydro pumped storage consumption', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation hydro run-of-river and poundage', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation hydro water reservoir', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation marine', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation nuclear', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation other', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation other renewable', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation solar', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation waste', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation wind offshore', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('generation wind onshore', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('weather_main', <DataTypes.CATEGORICAL: 1>, <InputTypes.OBSERVED_INPUT: 1>), ('weather_description_simplified', <DataTypes.CATEGORICAL: 1>, <InputTypes.OBSERVED_INPUT: 1>)]\n",
      "# input_size = 41\n",
      "# output_size = 1\n",
      "# category_counts = [8, 21]\n",
      "# input_obs_loc = [19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]\n",
      "# static_input_loc = []\n",
      "# known_regular_inputs = [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]\n",
      "# known_categorical_inputs = []\n",
      "# dropout_rate = 0.1\n",
      "# hidden_layer_size = 64\n",
      "# learning_rate = 0.0005\n",
      "# minibatch_size = 64\n",
      "# max_gradient_norm = 1.0\n",
      "# num_heads = 2\n",
      "# stack_size = 1\n",
      "# weight_decay = 0.001\n",
      "# use_tlf = True\n",
      "# tlf_replace_with_seasonal = False\n",
      "# err_target = True\n",
      "# num_non_static_historical_inputs = 38\n",
      "# num_non_static_future_inputs = 17\n",
      "training_step exists: True\n",
      "[CHK] final input_obs_loc = [19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]\n",
      "[TEST] QuantileLoss (mean over taus): 283.387726\n",
      "[TEST] NQL@0.1: 0.007312\n",
      "[TEST] NQL@0.5: 0.007252\n",
      "[TEST] NQL@0.9: 0.007165\n"
     ]
    }
   ],
   "source": [
    "from types import SimpleNamespace\n",
    "# ===== Config =====\n",
    "CKPT_DIR = \"lightning_logs/tft/version_E3\"\n",
    "CSV_PATH = \"data/electricty.csv\"   # CSV with hourly raw target / total load forecast (TLF)\n",
    "BATCH_SIZE = 256\n",
    "NUM_WORKERS = 2\n",
    "\n",
    "# ===== Utilities =====\n",
    "def find_ckpt(d):\n",
    "    # Prefer best/last, otherwise pick the newest .ckpt file\n",
    "    for n in (\"best-checkpoint.ckpt\", \"last.ckpt\"):\n",
    "        p = os.path.join(d, \"checkpoints\", n)\n",
    "        if os.path.exists(p): return p\n",
    "    cands = glob.glob(os.path.join(d, \"checkpoints\", \"*.ckpt\"))\n",
    "    if not cands: raise FileNotFoundError(f\"No ckpt in {d}/checkpoints\")\n",
    "    return max(cands, key=os.path.getmtime)\n",
    "\n",
    "def to_ns(x):\n",
    "    # Recursively convert dict to SimpleNamespace\n",
    "    return SimpleNamespace(**{k: to_ns(v) if isinstance(v, dict) else v for k, v in x.items()}) if isinstance(x, dict) else x\n",
    "\n",
    "def pick_col(df, cands):\n",
    "    # Pick the first existing column name from candidates\n",
    "    for c in cands:\n",
    "        if c in df.columns: return c\n",
    "    raise KeyError(f\"None of {cands} in columns: {list(df.columns)[:20]}\")\n",
    "\n",
    "def norm_hour(series):\n",
    "    # Normalize hour to 0..23 (handles 1..24 inputs as well)\n",
    "    s = pd.to_numeric(series, errors=\"coerce\").fillna(-1).astype(int)\n",
    "    return ((s - 1) % 24 if s.min() >= 1 and s.max() >= 24 else s % 24).astype(int)\n",
    "\n",
    "# ===== 1) Restore model (your __init__ takes positional hparams) =====\n",
    "ckpt = torch.load(find_ckpt(CKPT_DIR), map_location=\"cpu\")\n",
    "raw_hp = ckpt.get(\"hyper_parameters\", {})\n",
    "raw_hp = raw_hp.get(\"hparams\", raw_hp) if isinstance(raw_hp, dict) else raw_hp\n",
    "hparams = to_ns(raw_hp)\n",
    "\n",
    "tft = TemporalFusionTransformer(hparams)\n",
    "tft.load_state_dict(ckpt[\"state_dict\"], strict=False)\n",
    "tft.eval()\n",
    "\n",
    "# Key info\n",
    "is_err = bool(getattr(hparams, \"err_target\", False))   # True: model outputs residual err_target\n",
    "nd     = int(hparams.total_time_steps - hparams.num_encoder_steps)\n",
    "dec    = slice(-nd, None)\n",
    "\n",
    "# ===== 2) Forward pass on your existing test_dataset =====\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "\n",
    "# ===== 3) Rebuild decoder keys (id, day, hour) keeping original order (do NOT sort df_all) =====\n",
    "df_all = test_dataset.data.reset_index(drop=True).copy()\n",
    "idx_df = test_dataset.data_index.reset_index(drop=True)\n",
    "N = len(idx_df)\n",
    "\n",
    "ID_COL  = pick_col(df_all, [\"identifier\",\"targetidentifier\",\"id\",\"series_id\"])\n",
    "DAY_COL = pick_col(df_all, [\"days_from_start\",\"day_from_start\",\"days\"])\n",
    "H_COL   = pick_col(df_all, [\"hour\",\"hours\",\"hour_of_day\",\"hr\"])\n",
    "\n",
    "df_all[\"_hour_norm\"] = norm_hour(df_all[H_COL])\n",
    "df_all[\"_k\"] = df_all.groupby([ID_COL, DAY_COL]).cumcount()  # within-day order in original sequence\n",
    "\n",
    "ids_mat, day_mat, hour_mat, k_mat = [], [], [], []\n",
    "for r in idx_df.itertuples():\n",
    "    rng = np.arange(r.end_abs - nd, r.end_abs)  # decoder slice for this sample\n",
    "    ids_mat.append(  df_all.loc[rng, ID_COL].to_numpy() )\n",
    "    day_mat.append(  df_all.loc[rng, DAY_COL].to_numpy() )\n",
    "    hour_mat.append( df_all.loc[rng, \"_hour_norm\"].to_numpy() )\n",
    "    k_mat.append(    df_all.loc[rng, \"_k\"].to_numpy() )\n",
    "\n",
    "ids_mat  = np.stack(ids_mat,  axis=0)  # [N, nd]\n",
    "day_mat  = np.stack(day_mat,  axis=0)\n",
    "hour_mat = np.stack(hour_mat, axis=0)\n",
    "k_mat    = np.stack(k_mat,    axis=0)\n",
    "\n",
    "# ===== 4) Pull raw target and TLF from CSV and align by (id, day, hour) =====\n",
    "df_csv_raw = pd.read_csv(CSV_PATH)\n",
    "ID_C   = pick_col(df_csv_raw, [\"identifier\",\"targetidentifier\",\"id\",\"series_id\"])\n",
    "DAY_C  = pick_col(df_csv_raw, [\"days_from_start\",\"day_from_start\",\"days\"])\n",
    "H_C    = pick_col(df_csv_raw, [\"hour\",\"hours\",\"hour_of_day\",\"hr\"])\n",
    "TGT_C  = pick_col(df_csv_raw, [\"target\",\"power_usage\",\"load\",\"y\"])\n",
    "TLF_C  = pick_col(df_csv_raw, [\"total load forecast\",\"total_load_forecast\",\"tlf\",\"base\"])\n",
    "\n",
    "df_csv = df_csv_raw[[ID_C, DAY_C, H_C, TGT_C, TLF_C]].copy()\n",
    "df_csv[\"_hour_norm\"] = norm_hour(df_csv[H_C])\n",
    "df_csv = df_csv.rename(columns={ID_C:\"id\", DAY_C:\"day\"})\n",
    "df_csv = df_csv.dropna(subset=[\"day\"])\n",
    "df_csv[\"id\"]  = df_csv[\"id\"].astype(str)\n",
    "df_csv[\"day\"] = pd.to_numeric(df_csv[\"day\"], errors=\"coerce\").astype(int)\n",
    "df_csv = df_csv.drop_duplicates([\"id\",\"day\",\"_hour_norm\"])\n",
    "\n",
    "key_df = pd.DataFrame({\n",
    "    \"id\":  ids_mat.reshape(-1).astype(str),\n",
    "    \"day\": day_mat.reshape(-1).astype(np.int64),\n",
    "    \"hn\":  hour_mat.reshape(-1).astype(np.int64),\n",
    "})\n",
    "right = df_csv.rename(columns={\"_hour_norm\":\"hn\"})[[\"id\",\"day\",\"hn\", TGT_C, TLF_C]]\n",
    "joined = key_df.merge(right, on=[\"id\",\"day\",\"hn\"], how=\"left\")\n",
    "\n",
    "y_true_flat = joined[TGT_C].to_numpy()\n",
    "tlf_flat    = joined[TLF_C].to_numpy()\n",
    "\n",
    "# Fallback: if many missings, align by within-day order k (keep df_all order untouched)\n",
    "miss = np.isnan(y_true_flat).sum() + np.isnan(tlf_flat).sum()\n",
    "if miss > 0.1 * y_true_flat.size:\n",
    "    df_csv_sorted = df_csv.sort_values([\"id\",\"day\",\"_hour_norm\"]).copy()\n",
    "    df_csv_sorted[\"_k\"] = df_csv_sorted.groupby([\"id\",\"day\"]).cumcount()\n",
    "    key_df_k = pd.DataFrame({\n",
    "        \"id\":  ids_mat.reshape(-1).astype(str),\n",
    "        \"day\": day_mat.reshape(-1).astype(np.int64),\n",
    "        \"k\":   k_mat.reshape(-1).astype(np.int64),\n",
    "    })\n",
    "    right_k = df_csv_sorted[[\"id\",\"day\",\"_k\", TGT_C, TLF_C]].rename(columns={\"_k\":\"k\"})\n",
    "    joined  = key_df_k.merge(right_k, on=[\"id\",\"day\",\"k\"], how=\"left\")\n",
    "    y_true_flat = joined[TGT_C].to_numpy()\n",
    "    tlf_flat    = joined[TLF_C].to_numpy()\n",
    "\n",
    "expected = N * nd\n",
    "assert y_true_flat.size == expected and tlf_flat.size == expected, \"Alignment size mismatch\"\n",
    "y_true = y_true_flat.reshape(N, nd)\n",
    "tlf    = tlf_flat.reshape(N, nd)\n",
    "\n",
    "# ===== 5) Forward pass: get err_target or direct outputs (no inverse-scaling, no mapping) =====\n",
    "outs, taus, Q = [], None, None\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        (x_known, x_observed, x_static), _ = batch\n",
    "        if hasattr(tft, \"_prepare_tft_inputs\"):\n",
    "            all_inputs, _ = tft._prepare_tft_inputs(batch)\n",
    "            out = tft(all_inputs)\n",
    "        else:\n",
    "            out = tft(x_known, x_observed, x_static)\n",
    "        if out.dim() == 2: out = out.unsqueeze(-1)     # [B, nd, 1]\n",
    "        if Q is None:\n",
    "            Q = out.size(-1)\n",
    "            hp_q = getattr(getattr(tft, \"hparams\", None), \"quantiles\", None)\n",
    "            taus = list(hp_q) if isinstance(hp_q, (list, tuple)) and len(hp_q)==Q else ([0.5] if Q==1 else [0.1,0.5,0.9])\n",
    "        outs.append(out.cpu())\n",
    "outs = torch.cat(outs, dim=0).numpy()                  # [N, nd, Q]\n",
    "\n",
    "# Combine: err_target + TLF  (or use out directly)\n",
    "y_hat_q = (outs + tlf[:, :, None]) if is_err else outs  # no scaling/mapping applied\n",
    "\n",
    "# ===== 6) Compute QuantileLoss / NQL using your calculators =====\n",
    "ql_calc  = getattr(tft, \"train_criterion\", None)\n",
    "nql_calc = getattr(tft, \"test_criterion\",  None)\n",
    "if ql_calc is None or nql_calc is None:\n",
    "    raise RuntimeError(\"Missing QuantileLossCalculator / NormalizedQuantileLossCalculator (tft.train_criterion / tft.test_criterion).\")\n",
    "\n",
    "y_true_flat2 = y_true.reshape(-1)\n",
    "y_hat_flat_q = y_hat_q.reshape(-1, y_hat_q.shape[-1])\n",
    "\n",
    "targets_q = torch.tensor(np.repeat(y_true_flat2[:, None], y_hat_flat_q.shape[1], axis=1), dtype=torch.float32)\n",
    "preds_q   = torch.tensor(y_hat_flat_q, dtype=torch.float32)\n",
    "y_true_t  = torch.tensor(y_true_flat2, dtype=torch.float32)\n",
    "\n",
    "print(f\"[TEST] QuantileLoss (mean over taus): {ql_calc.apply(preds_q, targets_q).item():.6f}\")\n",
    "for j, tau in enumerate(taus):\n",
    "    print(f\"[TEST] NQL@{tau}: {nql_calc.apply(y_true_t, preds_q[:, j], tau).item():.6f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TFT PyTorch Kernel",
   "language": "python",
   "name": "tft-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "309px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
